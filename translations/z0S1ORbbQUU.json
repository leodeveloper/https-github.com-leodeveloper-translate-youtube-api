{
    "source": "z0S1ORbbQUU",
    "youtubelink": "https://www.youtube.com/watch?v=z0S1ORbbQUU",
    "t_english": "- Hi, everyone, Sal here, from Khan Academy, and as some of y'all know, I have released my second book, \"Brave New Words About the Future of AI in Education and Work.\" It's available wherever you might buy your books, but as part of the research for that book, I did some interviews with some fascinating people, which you are about to watch. So today we have Greg Brockman. I'm very excited to have you here, Greg. For those of you who don't know, Greg is the co-founder, chairman, and president of an organization that some folks are talking about these days called Open AI. And we, at Khan Academy, have done a little bit with OpenAI as well. And this is very exciting because this is the start of a new podcast, a new live stream, a new thing we're doing called Brave New Words, which is also a book that we're working on as well. So Greg, thanks so much for joining us. - Thank you for having me. - So let's just start, make sure everyone watching and listening has a shared understanding. Tell us a little bit about Open AI and how you decided to start it and maybe a little bit of where it's gone since then. - Yeah, so, you know, for me, I first got excited about the idea of AI when I read Alan Turing's 1950 paper on the Turing test, which, have you read Sal? - You know, I haven't read the paper. I'm very familiar with it, but not actually read the paper. - Okay. So I recommend reading it because, you know, the first half's all about the Turing test, but the second half is about how are you going to solve it? And he said, look, you're never gonna program an answer to this thing. It's just too hard. But you could build a machine that could learn. - And just to pause you, for folks who don't know, what was the Turing test? Just to make sure everyone's on the same page. - Yeah, the Turing test is the idea of could you distinguish between a machine and a person by having a judge who talks to a person, talks to a machine, and that if they're indistinguishable, you could say that that machine is really intelligent. And so, again, you have to like be able to not just sort of, you know, chitchat, you have to be able to, in his paper he says, okay, like the judge ask questions about chess and you have to answer chess questions. And so you realize that language really captures so much of the human experience and so much of what it means to be intelligent. And that I think his sort sort of, you know, that one of my co-founders says that Turing was touring for a reason. You know, he is truly, truly brilliant. One of his great insights is like, look, you're going to have to learn an answer. You're going to have to build a machine that could understand how to accomplish tasks. We cannot. And that for me was the moment it all clicked. But of course, this was like 2008, so nothing worked in AI and it wasn't for another seven years that looking from the outside at deep learning and the fact that computers had kind of gotten fast enough, that they were now commercially useful, that we started to realize that, look, maybe there's actually a shot at this dream. And you know, I and others came together because we wanted to see if we could steer AI technology in a positive way. Wanted to see if we could actually build the kind of machine Turing had talked about, a human level intelligence, what we call an AGI, and to have that be something that benefits all of humanity. So that's the mission of OpenAI. So we push forward the technology. We want to actually have it be beneficial, have it be safe, and distribute those benefits to everyone. So we've been working on it for eight years now, I think. And in that time, you know, we keep doing the same activity of, we just build a bigger neural network, we make it more capable, we make it more aligned, we make it safer. And over the past couple years, we've also started to deploy it and make it useful. And that's what I think is so interesting to me about this technology. It's not like fusion where it's like you either got it or you don't. It is each step along the way you can actually have impact and you can actually start benefiting people. And so I think that's good and you know, you get to see the benefits of what you've built and actually learn how to mitigate all the downsides. And so I think that's the stage that we're in. - Yeah, there's a bunch in that. I mean, you know, it sounds like based on when you are working on AI stuff, I'm a little over 10 years older or a little more than that, older than you. But you know, in the mid late nineties when I was in college, and you know, I was working with some of the early pioneers and some of them were my professors and it was the same thing. I was super excited about artificial intelligence. I'd read the science fiction, and I'm like, oh, this is gonna take forever, if it ever happens. And even to your point, you experienced the same about 10, 12 years later. And then even when y'all were thinking about starting OpenAI, this, you know, what you mentioned AGI, Artificial General Intelligence, I think many thoughtful people, if I'm honest, even myself, and I tend to run pretty optimistic about things, I would've thought that that's a little bit delusional, to actually now start working on a, like, you know, take it not even a research lab. I mean, I guess it's something of a research lab, but to actually start an organization that has a. Did you think that were people telling you that? How did you decide to do it anyway? - Oh yeah. I mean we got plenty of very, very negative feedback from the community. And the thing that I actually found most interesting was that we were talking about AI safety before it was cool. And in fact that I remember talking to a candidate who worked at a big AI lab who said, \"Yeah, I think that AGI safety is like the most important problem. I think it really matters. But if you ever quote me on that, I will deny everything.\" And I think that that is what set us apart is that we were really willing to think about where it goes and act on it. We're not alone. Like there are other people in the field, other pioneers who had been pushing forward this kind of technology and had, you know, sort of been also I think very sort of visionary in terms of thinking, you know, even many years ahead of us to get started on this problem. But I think that maybe, you know, I don't know if it's just something in our DNA or if it's something about just kind of the, you know, for me personally, I felt like I'd spent five years building a technology company. I was ready to really sign up for a problem that I was ready to work on for the rest of my life. And it was so clear to me that like if I could just make a little depth, even if we're talking like 300 years later and AGI comes along, it would be worth it. Right? And, you know, there's a chance that it would be even sooner. And so I think that is kind the framing is that the timeline, you can quibble it, you can debate it, you can talk about these things, but fundamentally signing up for the impact for the most important technology that humans will ever create. Like that's something I can get behind. - And what's notable, and I guess this isn't news to a lot of folks 'cause OpenAI has been in the news a lot lately is, you know, you have these GPT models, these, you know, generative pre-trained transformers, this technology that's, you know, a flavor of neural nets, which have been in the AI community for some time, and y'all had GPT-1, GPT-2, people said, oh, this is interesting, it can write, but it, you know, it doesn't really have a good handle on knowledge, GPT-3 even better. And then ChatGPT comes out, it's an interface, it starts to blow people's mind a little bit. And then obviously we announced with y'all, that we've been working together on, on GPT-4, on using it in Khan Academy, but y'all have obviously been doing all of the work to develop it. This notion of AGI, Artificial General Intelligence does not seem so outlandish anymore. You know, even some of what I think many folks have gotten GPT-4 to do starts to feel kinda like that. I guess my first question is, what do you think y'all are doing that let y'all get to this place that, you know, there's many, many folks working in the field, many larger organizations with more resources. Do you think it's something you're doing different or how you're approaching it or? Yeah, what do you think is special? - Yeah, I think it's a correct question. I mean, I do think we are part of a much larger trend, right? It's like much larger history, right? You look back at all the compute curves, for 70 years we had this exponential growth and you know, in like 2000 Ray Kurzweil was saying, hey, just look at the compute, that's gonna kind of tell you what's gonna be possible. That's the fuel for progress. And everyone thought he was crazy. And now I think they basically think that he's right. And I think that, you know, that you think about the amount of engineering that goes into us being able to deliver something like GPT-4, from the actual compute infrastructure to all of the data sets and tools that we use, that is really this massive endeavor of humanity in a lot of ways. But kind of specifically, you know, we've managed to execute because we brought together people from a research background and an engineering background. And I think that that is something that's very unique, right? And I think that, you know, safety is a core part of that that kind of comes from all the different angles. It's sort of, you know, both in practice and kind of in theory thinking about what, you know, how these systems are gonna behave, how they're going to go right and go wrong. But yeah, I think that the thing that was so interesting for me when we were starting, was looking at all the other labs, and you can really see that they come from typically a research first background. And so you have these research engineers who are told what to do, and the research scientists get to do whatever they want. And you're like, that doesn't seem like how you're going to actually build a working system. It seems like a great way to get a bunch of citations, but if you actually want to have an impact and to develop something, you just need to structure the organization differently. And it's hard, like it sounds easy on paper, but I there's these very conflicting ways of thinking about things if you come from a very practical background versus if you come from a more academic background. And we somehow have to lean into those. And I think that we've kind of solved more sophisticated versions of this sort of different mindsets, different backgrounds, problems, like many, many times. And you just never fully solve it. You move to a more sophisticated version of it. So I think it's this lean into the discomfort, lean into the hard parts. - No, there's so many questions I have there because I think what, you know, there is something unique that y'all must be doing. Y'all aren't that large of an organization and y'all are definitely, I guess punching above your weight. But one of the things that you've talked a lot about, and this was even one of the reasons to start OpenAI as a not-for-profit, and we'll talk a little bit about how things have evolved since then, but you keep mentioning safety and, you know, AI is both exciting and maybe even scary to some folks. We've all read the both exciting and the dystopian science fiction. When you talk about safety, what are you talking about? What are the real fears that folks should worry about and put constraints around and what are the ones that maybe aren't as justified? - Yeah, so I think there's been a long history of AI safety thinking, right? And I think there's some that predates, you know, goes back to the fifties, sixties. You can find people like Arthur C. Clark talking about this, of having an intelligent machine. And you know, what sets humans apart is the fact we are intelligent. And so it's something new, right? This whole idea. And so I think we should approach it with equal parts excitement for what can be accomplished and caution for where we could go wrong. So I think that is like fundamentally deeply correct, have these mixed feelings and to simultaneously be amazed by anything new, but also ask where is this going and where is this particular one? Where could the pitfalls be? I think that's the only way we can possibly navigate through the space correctly. But I think that another thing that's been very interesting is how surprising AI seems to be and how it plays out. Like you think about in the nineties everyone thought that, oh, if you just solve chess that will get you to AGI. And actually chess was kind of the first thing we solved in a lot of ways, and it didn't really go further. And I think I've seen the same on safety thinking, right? That if you think of it as, oh, like, you know, like one thing that could have been built, one direction that I think was possible, was that you'd build these agents that have to survive and replicate and evolve in some sort of complicated multi-agent simulation. That sounds really terrifying, right? To even know what those agents are capable of. And you know, to be able to trust them, you have to solve some really hard problems. And so a lot of effort goes into thinking about how do you design like a reward function that you write down very specifically that has no, be careful what you wish for to it. And so there's been a lot of thought that goes into those kinds of ways of solving problems, but the GPT paradigm kind of, no one saw it coming, it's just totally different from what you'd expect from a safety perspective. And so to me, the lesson really is this, to even know how to put a handle on the technology and to figure out what it could be used for and how to kind of steer it in the right way. Not that there's necessarily a limit to foresight, but that I think that we have a, we have a history of getting overconfident on the wrong things. And so, you know, an example where you can see a head is if you look at, for example, reinforcement learning from human preferences. And so this is what we use to actually tune the behaviors of these models. And that's something that's very different from say GPT-3, where we kind of release the model after just training it on the base dataset to GPT-4, where we're actually able to really tune it and sort of choose the values that the model exhibits. And we actually started developing that technology in 2017 before any of these models existed. And so I think that you can see a little bit ahead into the future. You should think about how they're going to be used, both making sure that they're aligned with what the operator wants, you know, however, the user is. That they're not sort of miusable if someone wants to do something, but society kind of has a society that that is illegal or is harmful to someone else, there should be some limits. And then also I think there's ecosystem effects where it's somehow, you can imagine that the AIs, they all do kind of what they're told to do locally, but it somehow adds up to a worse world. And so I think that we're going to have to sort of encounter a increasing series of stakes as time goes on. You know, we've sort of graduated in some ways fro the sort of risks of these models. For GPT-3, I think that we were really worried about misinformation, but when we really came down to it, we saw that people really just wanted to generate, that the most common abuse vector was generating medical advertisements for various drugs. And I think that with GPT-4, you have a new sort of class of risks and I think in the future that you'll have new classes of both benefits and risks that go hand in hand. - So, you know, obviously one of the things that, interesting about the two of us con talking in our organizations, y'all reached out to us back, you know, six months ago when y'all were just starting to get the first version of GPT-4. And I, I guess one question I have is, you know, why did you reach out to us back then? - Yeah, well, for me personally, I've always felt like one of the motivations for building AI systems, for trying to build AGIs, to get everyone a personal tutor, like I personally, I think many people have a story of that one teacher who really understood them, who helped them achieve and get excited about a subject. And you just imagine what would happen if everyone had access to such a tutor 24/7, who can really understand them and motivate them. And I feel like that is so aligned with what Khan Academy is building. And I, you know, that the potential that you want to unlock at every student. And so it was just like when we realized maybe we can actually make a dent in education, maybe this could be applied there. It was so clear that that Khan Academy was the first port of call. - And since then, you know, I guess as we've worked together, and obviously now the GPT-4 is out there, what are you hoping this becomes? Like how do you, how do you hope the education world leverages this? Famously when ChatGPT came out, it caused a lot of stress in the education world. People were like, oh, kids are gonna use this to cheat on their essays or do their homework. How should educators be thinking about this right now? - Yeah, I think that I would say that there's a sort of, you know, education specific version of what I've been saying generally, right? That there's opportunities, there's risks. And I think figuring out how to navigate that is really important. And you have to lean into that tension, right? So that, I think it is important that people learn to think for themselves, but I think it's also really important that students can be, you know, sort of get the best out of technology and that we're making this technology very accessible and available to people who may not be able to get great educational tools otherwise. And so I think that there's, you know, my hope is that we serve as a platform that teachers, educators are able to shape to their liking and to help sort of work with their students and to fill gaps that they can't. And so, you know, I think that the kinds of applications, I'd actually be kind of curious, Sal, what you've been seeing as the ones that you're most excited about. - Yeah. Well, you know, obviously, we've been putting a lot into this and we're very excited, you know, we've even demoed, you know, what we're calling Khanmigo, which is essentially the incarnation of the AI on Khan Academy with some large school districts, some of whom have famously banned ChatGPT. And there's, you know, they're giving us the feedback, this is what we wanted. We wanted to harness the powers of this technology, but put some guardrails around it, so that it's being used productively for students so that it, you know, teachers can kind of see what they're doing, that it's pedagogically sound now. Now it is interesting that it has created a really big debate where people are like, well this is great if they're within the sandbox, but then what's to stop them from going someplace else? And someone else is gonna create an application that uses the API to to do something, you know, here or there. So there, I think there are some real questions there. I guess maybe I'll turn that around as a question, how are y'all thinking about this in terms of, is it going to be a little bit like your classic app stores where there's a little bit of editorial review of how folks are using the API or is it going to be more of like, let you know, let's see what happens. How are y'all thinking about this? And I guess we could talk about education generally or education specifically or generally. - Yep. Well, I think that the truth is that this technology is very new and there's a lot to learn, right? But we're very thoughtful about it. We spend a lot of time thinking about exactly how people should build on our platforms, what the rules of engagement should be, trying to get lots of input. So we engage a lot with educators and with other people and in various spaces because I think ultimately the decision of how to integrate this kind of technology into the world, it's it should not just be up to us. Like we need to be part of that for sure, if it's our technology, but we think it's really important to get broad input from everyone. So that's actually one thing that I think is maybe the single most important factor. And so you should expect evolution, right? You should expect us to get data and realize that hey, like this particular thing played out great, this particular thing did not, and then learn how to adapt. So my hope is that, you know, number one, I think it's really important to really show the upside, right? That I think it's easy to just sort of only see the things that can go wrong. And I think it's important not to stick your head in the sand, but the reason we build this in the first place, right, is to actually realize those benefits. And so what I'm really excited to see is with Khan Academy or anyone else who's going to build in this space to really engage with like, going deep with districts, talking to educators and really figuring out what the exact shaping is that they want. Once you have a positive example of something working, it's easy to build standards around it, right? If you don't have that at all, then you're just shooting in the dark. And we've seen this already, you know, last republish a blog post about safety standards for deploying language models. And all of that came from two years worth of deployments and honestly getting a lot wrong. And so I think that this iterative deployment of learning from practice, that is, I think, the single most important thing that we can all be doing right now. - No, I completely agree. Clearly, you know, we're investing so much because we are generally very optimistic about where all of this is going. And you know, I couldn't speak openly about it when there were all these ChatGPT debates out in the media, but then once we were able to, I was saying, look, this, I know there has some fears, but if you put it in the right framework with the right guardrails, not only can you mitigate those risks, but you can have massive advances, a tutor for every student and just introduce completely new modalities that would've seemed like science fiction without AI, things like interview historical figure, practice your debate skills. You know, we could go, you know, teachers being able to help creating lesson plans, etcetera, etcetera. You know, one debate that I've been having with a lot of friends lately, you know, knowledgeable friends who know about AI, etcetera, we've been getting into this classical debate about is the tool going to diminish human capability or expand human capability? I'm on the side of expand. So, you know, that's where my cards are, that it's gonna make us more creative. In some weird way, it might actually make us write more because we're gonna be more editors and we're gonna be crafting more. But I, how do you think about that when people say, oh wow, you know, now people are just gonna one less thing that humans do, they're not gonna develop their writing skills, they're not gonna develop the creativity 'cause they're just gonna lean that much more on artificial intelligence for it. - Yep, I mean I'm definitely with you Sal. Like, I think that that the net effect is going to be extremely positive that I think that we're all going to get these AI superpowers, we can achieve things we couldn't otherwise. The drudgery will like drain away. All of those things I think are here, right? If not on the horizon. But of course it would be sticking your head in the sand to say that's only the only effect, right? I think it's like that's the net effect and I think it will be quite strong. But I think that there will be anecdotes of places where, you know, that yeah, it's like people who loved a particular craft and now that craft is commoditized, right? That there was a barrier to entry. You had to build up a skill and now anyone can do it. And on the one hand it's a beautiful thing, right? Because there's all these people whose now creativity can be unlocked, right? There's, you know, everyone, you know, I Just like you think about how many people have a smartphone? And so if you're able to get access to everyone who has a smartphone to very powerful AI and they can start creating in a way that before you'd have to like buy a bunch of professional software and you'd have to go to school and get a lot of training. Like you can see how that world is different. But in a lot of ways it's more positive, you know, on that. But I think this change and being prepared for that, like, that's a scary thing. And I think that that's something we should kind of go into eyes wide open. - Yeah, absolutely. And you know, just in the time we have left, every time I talk to you, you, you sometimes say, oh, and by the way Sal, we're also working on this. And then you tell, show me and I'm like, oh, that's a big deal. Like, you know, it's like, and there's more. Round us out this conversation just, you know, painting a picture for folks on like what is coming as much as you can talk about it and what you think are the implications and how y'all are trying to focus on one of those directions or another. - Yeah, well look, I think at the most high level, like we really are serious about this trajectory to AGI. Like we think that that is the trajectory that society is on, the world is on. I think it's a path that we've been on for a long time. If you look at all of these curves and you know, I think we've picked up the torch in a lot of ways and we feel it's our chief responsibility to not just build it, but to build it, right? And kind of on the short term, I think that you see things like, you know, GPD 4 has vision inputs. That's something that we're still just piloting with one partner. But I think that that will also be a new step function in terms of usability, right? That you'll be able to present documents, you'll be able to, you know, if you have a diagram that is part of, you know, the educational curriculum on Khan Academy and that understanding that diagram together with the students' question about it is important. You'll be able to do that. And so I think that we're just going to open up the accessibility in a lot of ways, you know, making this stuff run faster, cheaper, more accessibly. That's always a big focus for us. And really trying to improve. Like I think the thing that we're missing right now in a lot of ways is being able to generate new ideas, right? Being able to solve harder problems and all of that we're thinking about, we're exploring, and you know, again, doing so with our sort of safety first focus. - Yeah, well I gotta say Greg, you know, thanks so much for spending the time and bringing us on this journey because it really feels like we're living in a science fiction book and it's kind of one of these choose your own adventure science fiction books where it can go in different directions, but I think as long as there's enough people thinking about how we maximize the opportunity and the benefits and mitigate as many risks as possible, I am, and it sounds like you too we're pretty excited about what the world might be like because of this. - I am too, yeah, it was great chatting. - Great, thanks for joining. - Yep, thank you.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n",
    "t_urdu": "- ہیلو، سب، سال\nیہاں، خان اکیڈمی کی طرف سے، اور جیسا کہ آپ سب جانتے ہیں، میں نے\nاپنی دوسری کتاب، \"Brave New Words About the Future of AI in Education and Work\" جاری کی ہے۔ یہ دستیاب ہے جہاں سے\nآپ اپنی کتابیں خرید سکتے ہیں، لیکن اس کتاب کی تحقیق کے حصے کے طور پر، میں نے کچھ دلچسپ لوگوں کے ساتھ کچھ انٹرویو کیے\n، جنہیں آپ دیکھنے والے ہیں۔ تو آج ہمارے پاس گریگ بروک مین ہے۔ میں آپ کو یہاں پا کر بہت پرجوش ہوں، گریگ۔ آپ میں سے ان لوگوں کے لیے جو نہیں جانتے، گریگ ایک تنظیم کے شریک بانی، چیئرمین، اور صدر ہیں جس کے بارے میں کچھ لوگ\nان دنوں بات کر رہے ہیں جسے اوپن اے آئی کہتے ہیں۔ اور ہم نے، خان اکیڈمی میں، OpenAI کے ساتھ بھی\nتھوڑا سا کام کیا ہے۔ اور یہ بہت پرجوش ہے کیونکہ یہ\nایک نئے پوڈ کاسٹ کا آغاز ہے، ایک نیا لائیو سلسلہ، ایک نئی چیز جسے ہم کر رہے ہیں\nBrave New Words، جو کہ ایک کتاب بھی ہے جس\nپر ہم کام کر رہے ہیں۔ تو گریگ، ہمارے ساتھ شامل ہونے کا بہت بہت شکریہ۔ - مجھے رکھنے کے لئے آپ کا شکریہ. - تو آئیے شروع کریں، اس بات کو یقینی بنائیں کہ ہر دیکھنے اور سننے والے کی مشترکہ سمجھ ہے۔ ہمیں Open AI کے بارے میں تھوڑا سا بتائیں اور آپ نے اسے کیسے شروع کرنے کا فیصلہ کیا اور شاید اس کے بعد\nسے یہ کہاں چلا گیا ہے اس کا تھوڑا سا بتائیں۔ - ہاں، تو، آپ جانتے ہیں، میرے لیے، میں سب سے پہلے AI کے خیال کے بارے میں پرجوش ہوا جب میں نے ایلن ٹیورنگ کا 1950 کا ٹیورنگ ٹیسٹ پر پیپر پڑھا،\nآپ نے کون سا سال پڑھا ہے؟ - تم جانتے ہو، میں نے پیپر نہیں پڑھا ہے۔ میں اس سے بہت واقف ہوں، لیکن اصل میں کاغذ نہیں پڑھتا۔ - ٹھیک ہے۔ لہذا میں اسے پڑھنے کی سفارش کرتا ہوں\nکیونکہ، آپ جانتے ہیں، پہلا نصف\nٹورنگ ٹیسٹ کے بارے میں ہے، لیکن دوسرا نصف اس بارے میں ہے کہ آپ اسے کیسے حل کرنے جا رہے ہیں؟ اور اس نے کہا، دیکھو، تم\nاس چیز کا جواب کبھی بھی پروگرام نہیں کرو گے۔ یہ صرف بہت مشکل ہے۔ لیکن آپ ایک ایسی مشین بنا سکتے ہیں\nجو سیکھ سکے۔ - اور صرف آپ کو روکنے کے لیے، ان\nلوگوں کے لیے جو نہیں جانتے، ٹورنگ ٹیسٹ کیا تھا؟ بس یہ یقینی بنانے کے لیے کہ\nہر کوئی ایک ہی صفحے پر ہے۔ - جی ہاں، ٹورنگ ٹیسٹ کا\nخیال ہے کہ کیا آپ ایک جج کے ذریعے مشین اور ایک شخص کے درمیان فرق کر سکتے ہیں\nجو کسی شخص سے بات کرتا ہے، مشین سے بات کرتا ہے، اور یہ کہ اگر وہ\nالگ نہیں ہیں، تو آپ کہہ سکتے ہیں کہ وہ مشین واقعی ہے  ذہین اور اسی طرح، ایک بار پھر، آپ کو یہ پسند کرنا ہوگا کہ\nصرف چھانٹنا ہی نہیں، آپ جانتے ہیں، چِٹ چیٹ،\nآپ کو اس قابل ہونا پڑے گا، اس کے پیپر میں وہ کہتا ہے، ٹھیک ہے، جیسے جج شطرنج کے بارے میں سوالات پوچھتا ہے اور آپ کو شطرنج کا جواب دینا ہوگا۔  سوالات اور اس طرح آپ کو احساس ہوتا ہے کہ\nزبان واقعی انسانی تجربے اور\nذہین ہونے کا بہت زیادہ مطلب حاصل کرتی ہے۔ اور یہ کہ مجھے لگتا ہے کہ اس کی طرح،\nآپ جانتے ہیں، کہ میرے شریک بانی میں سے ایک کا کہنا ہے کہ ٹورنگ ایک وجہ سے دورہ کر رہا تھا۔ تم جانتے ہو، وہ واقعی، واقعی شاندار ہے. اس کی عظیم بصیرت میں سے ایک ہے، دیکھو، آپ کو جواب سیکھنا پڑے گا۔ آپ کو ایک مشین بنانا ہوگی جو سمجھ سکے کہ\nکاموں کو کیسے پورا کیا جائے۔ ہم نہیں کر سکتے۔ اور یہ میرے لئے وہ\nلمحہ تھا جب یہ سب کلک ہوا۔ لیکن یقیناً، یہ 2008 کی طرح تھا،\nاس لیے AI میں کچھ کام نہیں ہوا اور یہ مزید سات سال تک نہیں ہوا کہ\nباہر سے گہری سیکھنے پر غور کیا جائے اور یہ حقیقت کہ کمپیوٹرز نے\nکافی تیزی سے کام کر لیا ہے، کہ اب وہ تجارتی طور پر کارآمد ہو چکے ہیں، کہ ہم نے محسوس کرنا شروع کر دیا کہ، دیکھو، شاید\nاس خواب میں واقعی کوئی شاٹ ہے۔ اور آپ جانتے ہیں، میں اور دوسرے اکٹھے ہوئے کیونکہ ہم یہ دیکھنا چاہتے تھے کہ آیا\nہم AI ٹیکنالوجی کو مثبت انداز میں چلا سکتے ہیں۔  یہ دیکھنا چاہتا تھا کہ کیا ہم\nواقعی اس قسم کی مشین بنا سکتے ہیں جس کے بارے میں ٹورنگ نے بات کی تھی، ایک انسانی سطح کی ذہانت،\nجسے ہم AGI کہتے ہیں، اور یہ ایسی چیز ہو\nجس سے پوری انسانیت کو فائدہ ہو۔ تو یہ OpenAI کا مشن ہے۔ لہذا ہم ٹیکنالوجی کو آگے بڑھاتے ہیں۔ ہم اصل میں یہ\nفائدہ مند ہونا چاہتے ہیں، یہ محفوظ رہیں، اور ان فوائد کو ہر ایک میں تقسیم کریں۔ تو اب ہم آٹھ سالوں سے اس پر کام کر رہے ہیں،\nمیرے خیال میں۔ اور اس وقت، آپ جانتے ہیں، ہم اسی سرگرمی کو کرتے رہتے ہیں، ہم صرف ایک بڑا نیورل نیٹ ورک بناتے ہیں، ہم اسے مزید قابل بناتے ہیں، ہم اسے مزید سیدھ میں رکھتے ہیں، ہم اسے محفوظ بناتے ہیں۔ اور پچھلے دو سالوں میں، ہم نے\nاسے تعینات کرنا اور اسے کارآمد بنانا بھی شروع کر دیا ہے۔ اور یہ وہی ہے جو مجھے لگتا ہے کہ اس ٹیکنالوجی کے بارے میں میرے لئے بہت دلچسپ ہے. یہ فیوژن کی طرح نہیں ہے جہاں یہ ایسا ہے جیسے آپ کو یہ مل گیا یا آپ کو نہیں ہے۔ یہ اس راستے میں ہر قدم ہے جس پر\nآپ واقعی اثر ڈال سکتے ہیں اور آپ\nلوگوں کو فائدہ پہنچانا شروع کر سکتے ہیں۔ اور اس لیے مجھے لگتا ہے کہ یہ اچھی بات ہے اور آپ جانتے ہیں، آپ نے جو کچھ بنایا ہے اس کے فوائد آپ کو دیکھنے کو ملتے ہیں\n اور درحقیقت\nتمام نشیب و فراز کو کم کرنے کا طریقہ سیکھتے ہیں۔ اور اس لیے مجھے لگتا ہے کہ یہ\nوہ مرحلہ ہے جس میں ہم ہیں۔ - ہاں، اس میں ایک گروپ ہے۔ میرا مطلب ہے، آپ جانتے ہیں، ایسا لگتا ہے کہ جب\nآپ AI چیزوں پر کام کر رہے ہیں، میں آپ سے 10 سال بڑا ہوں یا اس سے تھوڑا زیادہ،\nآپ سے بڑا ہوں۔ لیکن آپ جانتے ہیں، نوے کی دہائی کے وسط میں جب میں کالج میں تھا، اور آپ جانتے ہیں، میں ابتدائی علمبرداروں میں سے کچھ کے ساتھ کام کر رہا تھا\n اور ان میں سے کچھ میرے پروفیسر تھے اور یہ ایک ہی بات تھی۔ میں مصنوعی ذہانت کے بارے میں بہت پرجوش تھا۔\n میں سائنس فکشن پڑھوں گا، اور میں ایسا ہی ہوں، اوہ، یہ\nہمیشہ کے لیے لے جائے گا، اگر کبھی ایسا ہوتا ہے۔ اور یہاں تک کہ آپ کی بات تک، آپ نے\nتقریباً 10، 12 سال بعد ایسا ہی تجربہ کیا۔ اور پھر اس وقت بھی جب آپ OpenAI\nشروع کرنے کے بارے میں سوچ رہے تھے، یہ، آپ جانتے ہیں، آپ نے\nAGI، مصنوعی جنرل انٹیلی جنس کا کیا ذکر کیا، میرے خیال میں بہت سے سوچنے والے لوگ،\nاگر میں ایماندار ہوں، یہاں تک کہ میں خود بھی، اور میں اس کے\nبارے میں کافی پرامید رہتا ہوں۔  چیزیں، میں نے سوچا ہو گا کہ یہ\nتھوڑا سا فریب ہے، حقیقت میں اب\nایک پر کام شروع کرنا، جیسے، آپ جانتے ہیں، اسے ایک ریسرچ لیب بھی نہ سمجھیں۔ میرا مطلب ہے، میرا اندازہ ہے کہ یہ\nایک تحقیقی لیب کی چیز ہے، لیکن حقیقت میں ایک ایسی\nتنظیم شروع کرنے کے لیے جس میں اے۔ کیا آپ نے سوچا کہ\nلوگ آپ کو یہ کہہ رہے تھے؟ آپ نے ویسے بھی ایسا کرنے کا فیصلہ کیسے کیا؟ - ارے ہان۔ میرا مطلب ہے کہ ہمیں کمیونٹی کی طرف سے کافی\n، بہت منفی تاثرات ملے۔ اور جو چیز مجھے درحقیقت\nسب سے زیادہ دلچسپ لگی وہ یہ تھی کہ ہم\nٹھنڈا ہونے سے پہلے AI سیفٹی کے بارے میں بات کر رہے تھے۔ اور حقیقت یہ ہے کہ مجھے\nایک امیدوار سے بات کرنا یاد ہے جس نے ایک بڑی AI لیب میں کام کیا تھا جس نے کہا تھا، \"ہاں، میں سمجھتا ہوں کہ AGI سیفٹی سب سے اہم مسئلہ کی طرح ہے۔ مجھے لگتا ہے کہ یہ واقعی اہمیت رکھتا ہے۔ لیکن اگر آپ کبھی اس پر میرا حوالہ دیتے ہیں،\nمیں ہر چیز سے انکار کر دوں گا۔\" اور میں سمجھتا ہوں کہ یہی وہ چیز ہے جس نے ہمیں الگ کیا ہے کہ ہم واقعی یہ\nسوچنے کے لیے تیار تھے کہ یہ کہاں جاتا ہے اور اس پر عمل کرتا ہے۔ ہم اکیلے نہیں ہیں۔ جیسا کہ میدان میں دوسرے لوگ ہیں، دوسرے علمبردار جو\nاس قسم کی ٹیکنالوجی کو آگے بڑھا رہے تھے اور وہ بھی تھے، آپ کو معلوم ہے، میں بھی سوچنے کے\nلحاظ سے بہت ہی بصیرت والا سمجھتا ہوں، آپ جانتے ہیں،\nیہاں تک کہ ہم سے کئی سال آگے ہیں۔ اس مسئلہ پر شروع کرنے کے لئے. لیکن مجھے لگتا ہے کہ شاید، آپ جانتے ہیں، میں نہیں جانتا کہ یہ\nہمارے ڈی این اے میں صرف کچھ ہے یا اگر یہ صرف اس قسم کے بارے میں کچھ ہے،\nآپ جانتے ہیں، ذاتی طور پر، میں نے محسوس کیا\nکہ میں نے ایک ٹیکنالوجی بنانے میں پانچ سال گزارے ہوں گے۔  کمپنی میں واقعی اس مسئلے کے لیے سائن اپ کرنے کے لیے تیار تھا\nجس پر میں اپنی باقی زندگی کے لیے کام کرنے کے لیے تیار تھا۔ اور یہ میرے لیے اتنا واضح تھا کہ اگر میں تھوڑی سی گہرائی کر سکتا ہوں،\n چاہے ہم 300 سال بعد کی طرح بات کر رہے ہوں اور AGI ساتھ آئے تو یہ اس کے قابل ہوگا۔ ٹھیک ہے؟ اور، آپ جانتے ہیں، ایک موقع ہے کہ یہ اور بھی جلد ہو جائے گا۔ اور اس لیے میں سمجھتا ہوں کہ یہ قسم کی\nفریمنگ ہے کہ ٹائم لائن، آپ اس پر بحث کر سکتے ہیں،\nآپ اس پر بحث کر سکتے ہیں، آپ ان چیزوں کے بارے میں بات کر سکتے ہیں، لیکن بنیادی طور پر اس اہم ترین ٹیکنالوجی کے\nاثرات کے لیے سائن اپ کرنا جو انسان کبھی تخلیق کریں گے۔ جیسے کہ میں اس سے پیچھے رہ سکتا ہوں۔ - اور جو بات قابل ذکر ہے، اور میرا اندازہ ہے کہ یہ\nبہت سارے لوگوں کے لیے خبر نہیں ہے کیونکہ OpenAI\nحال ہی میں بہت زیادہ خبروں میں ہے، آپ جانتے ہیں، آپ کے پاس یہ\nGPT ماڈلز ہیں، یہ، آپ کو معلوم ہے، جنریٹیو پری ٹرینڈ ٹرانسفارمرز\nیہ ٹیکنالوجی، جو آپ جانتے ہیں، نیورل نیٹس کا ذائقہ ہے، جو کہ\nکچھ عرصے سے AI کمیونٹی میں ہے، اور آپ سب کے پاس GPT-1، GPT-2 تھا، لوگوں نے کہا، اوہ، یہ دلچسپ ہے، یہ لکھ سکتا ہے  ، لیکن یہ، آپ جانتے ہیں، اس کا علم پر واقعی اچھا ہینڈل نہیں ہے،\nGPT-3 اور بھی بہتر۔ اور پھر چیٹ جی پی ٹی\nسامنے آتا ہے، یہ ایک انٹرفیس ہے، یہ لوگوں کے\nذہنوں کو تھوڑا سا اڑا دینے لگتا ہے۔ اور پھر ظاہر ہے کہ ہم نے\nآپ سب کے ساتھ اعلان کیا، کہ ہم\nGPT-4 پر، خان اکیڈمی میں اسے استعمال کرنے پر مل کر کام کر رہے ہیں، لیکن آپ سب نے ظاہر ہے کہ اسے تیار کرنے کے لیے تمام کام کر رہے ہیں۔ AGI، مصنوعی جنرل انٹیلی جنس کا یہ تصور\n اب اتنا اجنبی نہیں لگتا۔ آپ جانتے ہیں، یہاں تک کہ\nجو کچھ میرے خیال میں بہت سے لوگوں نے GPT-4 حاصل کر لیا ہے وہ ایسا محسوس کرنے لگتا ہے۔ میرا اندازہ ہے کہ میرا پہلا سوال یہ ہے کہ، آپ کے خیال میں آپ سب کیا\nکر رہے ہیں جس سے آپ سب کو اس مقام تک پہنچنے دیں،\nآپ جانتے ہیں، اس میدان میں بہت سے لوگ کام کر رہے ہیں، بہت سی بڑی تنظیمیں ہیں جن کے پاس\nزیادہ وسائل ہیں۔ کیا آپ کو لگتا ہے کہ یہ کوئی ایسی چیز ہے جسے\nآپ مختلف کر رہے ہیں یا آپ اس تک کیسے پہنچ رہے ہیں یا؟ ہاں، آپ کے خیال میں کیا خاص ہے؟ - ہاں، مجھے لگتا ہے کہ یہ ایک درست سوال ہے۔ میرا مطلب ہے، مجھے لگتا ہے کہ ہم ایک بہت بڑے رجحان کا حصہ ہیں، ٹھیک ہے؟ یہ بہت بڑی تاریخ کی طرح ہے، ٹھیک ہے؟ آپ تمام کمپیوٹ منحنی خطوط پر نظر ڈالیں، 70 سالوں سے ہمارے پاس\nیہ تیزی سے اضافہ تھا اور آپ جانتے ہیں، 2000 کی طرح\nرے کرزویل کہہ رہے تھے، ارے، ذرا حساب کو دیکھیں، یہ آپ کو بتائے گا کہ\nکیا ممکن ہے۔ یہی ترقی کا ایندھن ہے۔ اور سب نے سوچا کہ وہ پاگل ہے۔ اور اب مجھے لگتا ہے کہ وہ بنیادی طور پر\nسوچتے ہیں کہ وہ صحیح ہے۔ اور مجھے لگتا ہے کہ، آپ جانتے ہیں،\nکہ آپ انجینئرنگ کی اس مقدار کے بارے میں سوچتے ہیں جو\nہم میں GPT-4 جیسی چیز فراہم کرنے کے قابل ہوتی ہے، اصل کمپیوٹ\nانفراسٹرکچر سے لے کر ان تمام ڈیٹا سیٹس اور ٹولز تک جو ہم استعمال کرتے ہیں، یہ واقعی ہے۔ بہت سے طریقوں سے انسانیت کی یہ بڑی کوشش۔ لیکن خاص طور پر،\nآپ جانتے ہیں، ہم اس پر عملدرآمد کرنے میں کامیاب ہو گئے ہیں کیونکہ ہم نے\n تحقیقی پس منظر\nاور انجینئرنگ کے پس منظر سے تعلق رکھنے والے لوگوں کو اکٹھا کیا ہے۔ اور مجھے لگتا ہے کہ یہ ایسی چیز ہے جو بہت منفرد ہے، ٹھیک ہے؟ اور مجھے لگتا ہے کہ، آپ جانتے ہیں،\nحفاظت اس کا ایک بنیادی حصہ ہے کہ اس قسم کے\nتمام مختلف زاویوں سے آتے ہیں۔ یہ اس طرح کا ہے، آپ جانتے ہیں، عملی طور پر اور نظریہ میں دونوں طرح کے بارے میں\nسوچتے ہیں کہ کیا، آپ جانتے ہیں، یہ نظام کس طرح برتاؤ کرنے والے ہیں، وہ کیسے\nصحیح اور غلط ہونے جا رہے ہیں۔ لیکن ہاں، مجھے لگتا ہے کہ\nجو چیز میرے لیے بہت دلچسپ تھی جب ہم شروع کر رہے تھے، وہ دوسری تمام\nلیبز کو دیکھ رہی تھی، اور آپ واقعی دیکھ سکتے ہیں کہ وہ عام طور پر\nتحقیق کے پہلے پس منظر سے آتے ہیں۔ اور اس طرح آپ کے پاس یہ ریسرچ انجینئرز ہیں جن کو بتایا جاتا ہے کہ کیا کرنا ہے، اور ریسرچ سائنسدانوں کو\nجو چاہیں کرنے کو ملتے ہیں۔ اور آپ ایسے ہیں، ایسا نہیں\nلگتا کہ آپ اصل میں ورکنگ سسٹم کیسے بنائیں گے۔  ایسا لگتا ہے کہ \nحوالہ جات کا ایک گروپ حاصل کرنے کا یہ ایک بہترین طریقہ ہے، لیکن اگر آپ واقعی میں اثر ڈالنا چاہتے ہیں اور کچھ تیار کرنا چاہتے ہیں، تو آپ کو صرف تنظیم کو مختلف طریقے سے تشکیل دینے کی ضرورت ہے۔ اور یہ مشکل ہے، جیسا کہ یہ\nکاغذ پر آسان لگتا ہے، لیکن میرے پاس چیزوں کے بارے میں سوچنے کے یہ بہت متضاد طریقے ہیں اگر\nآپ ایک بہت ہی عملی پس منظر سے آتے ہیں اور اگر آپ زیادہ علمی پس منظر سے آتے ہیں۔ اور ہمیں کسی نہ کسی طرح ان میں جھکنا پڑے گا۔ اور مجھے لگتا ہے کہ ہم نے اس\n طرح کے\nمختلف ذہنیتوں، مختلف پس منظروں،\nمسائل، جیسے بہت سے، کئی بار حل کیے ہیں۔ اور آپ اسے کبھی بھی مکمل طور پر حل نہیں کرتے ہیں۔ آپ\nاس کے زیادہ نفیس ورژن کی طرف بڑھتے ہیں۔ تو مجھے لگتا ہے کہ یہ\nتکلیف میں جھکاؤ ہے، سخت حصوں میں جھکاؤ۔ - نہیں، میرے پاس بہت سارے\nسوالات ہیں کیونکہ میں سوچتا ہوں کہ کیا، آپ\nجانتے ہیں، وہاں کچھ انوکھا ہے جو آپ سب کو کرنا چاہیے۔ آپ سب ایک تنظیم کے اتنے بڑے نہیں ہیں اور آپ سب یقینی طور پر ہیں، میرا اندازہ ہے کہ آپ کے وزن سے زیادہ مکے مار رہے ہیں۔ لیکن ان چیزوں میں سے ایک جس کے\nبارے میں آپ نے بہت بات کی ہے، اور یہ بھی\nOpenAI کو غیر منافع بخش کے طور پر شروع کرنے کی ایک وجہ تھی، اور\nہم اس کے بارے میں تھوڑی بات کریں گے کہ اس کے بعد سے چیزیں کیسے تیار ہوئی ہیں، لیکن  آپ حفاظت کا تذکرہ کرتے رہتے ہیں اور، آپ جانتے ہیں، AI دونوں پرجوش ہے اور شاید کچھ لوگوں کے لیے خوفناک بھی۔ ہم سب نے دلچسپ اور ڈسٹوپین سائنس فکشن دونوں پڑھے ہیں۔ جب آپ حفاظت کے بارے میں بات کرتے ہیں، تو آپ کس کے بارے میں بات کر رہے ہیں؟  وہ کون سے حقیقی خوف ہیں جن کے\nبارے میں لوگوں کو فکر کرنا چاہئے اور رکاوٹیں ڈالنا چاہئے اور وہ کون سے ہیں جو\nشاید جائز نہیں ہیں؟ - ہاں، تو مجھے لگتا ہے کہ\n AI حفاظتی سوچ کی ایک طویل تاریخ رہی ہے، ٹھیک ہے؟ اور مجھے لگتا ہے کہ کچھ ایسی چیزیں ہیں\nجو پیش گوئی کرتی ہیں، آپ جانتے ہیں، پچاس، ساٹھ کی دہائی تک واپس جاتی ہے۔ آپ آرتھر سی کلارک جیسے لوگوں کو\n ایک ذہین مشین رکھنے کے بارے میں بات کرتے ہوئے پا سکتے ہیں۔ اور آپ جانتے ہیں، جو چیز انسانوں کو الگ کرتی ہے وہ حقیقت ہے کہ ہم ذہین ہیں۔ اور تو یہ کچھ نیا ہے، ٹھیک ہے؟ یہ سارا خیال۔ اور اس لیے میں سمجھتا ہوں کہ ہمیں کیا حاصل کیا جا سکتا ہے اس کے لیے مساوی جوش و خروش کے ساتھ اس سے رجوع کرنا چاہیے\n اور جہاں ہم غلط ہو سکتے ہیں اس کے لیے احتیاط کرنی چاہیے۔ تو مجھے لگتا ہے کہ یہ\nبنیادی طور پر گہرائی سے درست ہے، یہ ملے جلے احساسات ہیں اور ساتھ ہی\nکسی نئی چیز سے حیران رہ جائیں گے، لیکن یہ بھی پوچھیں کہ یہ کہاں جا رہا ہے اور یہ خاص کہاں ہے؟ خرابیاں کہاں ہو سکتی ہیں؟ میرے خیال میں یہ واحد راستہ ہے جس سے\nہم ممکنہ طور پر خلا میں صحیح طریقے سے تشریف لے سکتے ہیں۔ لیکن مجھے لگتا ہے کہ ایک اور چیز جو بہت دلچسپ رہی ہے وہ یہ ہے کہ\nAI کتنا حیران کن لگتا ہے اور یہ کیسے چلتا ہے۔ جیسا کہ آپ نوے کی دہائی کے بارے میں سوچتے ہیں\nسب نے سوچا کہ، اوہ، اگر آپ صرف شطرنج کو حل کرتے ہیں\nجو آپ کو AGI تک پہنچا دے گا۔ اور درحقیقت شطرنج پہلی چیز تھی جسے ہم نے\nبہت سے طریقوں سے حل کیا، اور یہ واقعی مزید آگے نہیں بڑھی۔ اور مجھے لگتا ہے کہ میں نے\nحفاظتی سوچ پر بھی ایسا ہی دیکھا ہے، ٹھیک ہے؟ کہ اگر آپ اس کے بارے میں سوچتے ہیں،\nاوہ، جیسے، آپ جانتے ہیں، ایک ایسی چیز کی طرح جو تعمیر کی جا سکتی تھی، ایک سمت جو میرے خیال میں ممکن تھی، وہ یہ تھی کہ آپ ان ایجنٹوں کو بنائیں گے جنہیں زندہ رہنا ہے اور نقل کرنا ہے اور کچھ میں ارتقاء کرنا ہے۔  پیچیدہ کثیر ایجنٹ تخروپن کی طرح. یہ واقعی خوفناک لگتا ہے، ٹھیک ہے؟ یہاں تک کہ یہ جاننے کے لیے کہ وہ\nایجنٹ کیا اہل ہیں۔ اور آپ جانتے ہیں، ان پر بھروسہ کرنے کے لیے، آپ کو کچھ\nواقعی مشکل مسائل کو حل کرنا ہوگا۔ اور اس لیے بہت ساری کوششیں اس\nبارے میں سوچنے میں پڑتی ہیں کہ آپ انعامی فنکشن کی طرح کیسے ڈیزائن کرتے ہیں جسے آپ خاص\nطور پر لکھتے ہیں جس میں کوئی نہیں ہے، محتاط رہیں کہ آپ اس کے لیے کیا چاہتے ہیں۔ اور اس طرح \nمسائل کو حل کرنے کے اس قسم کے طریقوں پر بہت زیادہ سوچ بچار کی گئی ہے، لیکن GPT پیراڈائم کی قسم،\nکسی نے اسے آتے نہیں دیکھا، یہ اس سے بالکل مختلف ہے جس کی آپ\nحفاظتی نقطہ نظر سے توقع کرتے ہیں۔ اور اسی طرح میرے نزدیک، سبق واقعی یہ ہے، یہاں تک کہ یہ جاننا کہ ٹیکنالوجی پر ہینڈل کیسے لگانا ہے\n اور یہ جاننا کہ\nاسے کس کے لیے استعمال کیا جا سکتا ہے اور\nاسے صحیح طریقے سے کیسے چلانا ہے۔  ایسا نہیں ہے کہ ضروری طور پر\nدور اندیشی کی کوئی حد ہوتی ہے، لیکن یہ کہ میں سمجھتا ہوں کہ ہمارے پاس غلط چیزوں پر حد سے زیادہ اعتماد کرنے کی تاریخ ہے۔ اور اسی طرح، آپ جانتے ہیں، ایک مثال جہاں آپ سر دیکھ سکتے ہیں،\nاگر آپ دیکھیں، مثال کے طور پر، \nانسانی ترجیحات سے کمک سیکھنا۔ اور اسی طرح ہم \nان ماڈلز کے طرز عمل کو حقیقت میں ٹیون کرنے کے لیے استعمال کرتے ہیں۔ اور یہ وہ چیز ہے جو\nGPT-3 کہنے سے بہت مختلف ہے، جہاں ہم ماڈل کو صرف\nبیس ڈیٹاسیٹ پر GPT-4 پر تربیت دینے کے بعد ریلیز کرتے ہیں، جہاں ہم\nواقعی اس کو ٹیون کرنے کے قابل ہوتے ہیں اور اس طرح کی اقدار کا انتخاب کرتے ہیں\nجو  ماڈل کی نمائش. اور ہم نے حقیقت میں اس ٹیکنالوجی کو 2017 میں تیار کرنا شروع کر دیا تھا اس سے پہلے کہ ان میں سے\nکوئی بھی ماڈل موجود ہو۔ اور اس لیے مجھے لگتا ہے کہ آپ مستقبل میں\nتھوڑا سا آگے دیکھ سکتے ہیں۔ آپ کو اس کے بارے میں سوچنا چاہیے کہ وہ کس طرح\nاستعمال کیے جائیں گے، دونوں اس بات کو یقینی بناتے ہوئے کہ وہ آپریٹر کی مرضی کے مطابق ہیں، آپ جانتے ہیں، تاہم، صارف ہے۔ کہ اگر کوئی کچھ کرنا چاہتا ہے تو وہ اس طرح کے قابل استعمال نہیں ہیں، لیکن معاشرے کا ایک ایسا\nمعاشرہ ہے جو غیر قانونی ہے یا کسی اور کے لیے نقصان دہ ہے، اس کی\nکچھ حدود ہونی چاہئیں۔ اور پھر میں یہ بھی سوچتا ہوں کہ\nماحولیاتی نظام کے اثرات ہیں جہاں یہ کسی نہ کسی طرح ہے، آپ\nتصور کر سکتے ہیں کہ AIs، وہ سب وہی کرتے ہیں جو\nانہیں مقامی طور پر کرنے کے لیے کہا جاتا ہے، لیکن یہ کسی نہ کسی طرح ایک بدتر دنیا میں اضافہ کرتا ہے۔ اور اس لیے میں سمجھتا ہوں کہ وقت گزرنے کے ساتھ ساتھ ہمیں داؤ کی\n بڑھتی ہوئی سیریز کا سامنا کرنا پڑے گا۔ آپ جانتے ہیں، ہم نے ان ماڈلز کے خطرات سے\nکچھ طریقوں سے گریجویشن کیا ہے۔ GPT-3 کے لیے، میں سمجھتا ہوں کہ ہم واقعی غلط معلومات کے بارے میں فکر مند تھے، لیکن جب ہم واقعی اس پر اتر آئے، تو ہم نے دیکھا کہ لوگ واقعی\nصرف پیدا کرنا چاہتے ہیں، کہ سب سے عام بدسلوکی\nویکٹر مختلف ادویات کے لیے طبی اشتہارات تیار کر رہا تھا۔ اور میں سمجھتا ہوں کہ GPT-4 کے ساتھ،\nآپ کے پاس خطرات کی ایک نئی قسم ہے اور میں سمجھتا ہوں کہ مستقبل میں آپ کے پاس\nفوائد اور خطرات دونوں کی نئی کلاسیں ہوں گی جو ساتھ ساتھ چلتے ہیں۔ - تو، آپ جانتے ہیں، ظاہر ہے کہ ان\nچیزوں میں سے ایک، جو ہم \nدونوں کی اپنی تنظیموں میں بات کرنے کے بارے میں دلچسپ ہے، آپ سب نے ہم سے رابطہ کیا، آپ کو معلوم ہے، چھ مہینے پہلے جب\nآپ سب کو ملنا شروع ہوا تھا۔ GPT-4 کا پہلا ورژن۔ اور میں، میرا اندازہ ہے کہ میرا ایک سوال ہے،\nآپ جانتے ہیں، آپ نے اس وقت ہم سے کیوں رابطہ کیا؟ - ہاں، ٹھیک ہے، ذاتی طور پر میرے لیے،\nمیں نے ہمیشہ \nAI سسٹمز بنانے، AGIs بنانے کی کوشش، ہر ایک کو ذاتی ٹیوٹر حاصل کرنے کے محرکات میں سے ایک کی طرح محسوس کیا ہے، جیسا کہ میں ذاتی طور پر، مجھے لگتا ہے کہ\nبہت سے لوگوں کے پاس اس کی کہانی ہے۔  ایک استاد جو\nواقعی انہیں سمجھتا تھا، جس نے ان کی مدد کی اور\nکسی موضوع کے بارے میں پرجوش ہو گئے۔ اور آپ ذرا تصور کریں کہ کیا\nہوگا اگر ہر ایک کو 24/7 ایسے ٹیوٹر تک رسائی حاصل ہو، جو انہیں واقعی سمجھ سکے\nاور ان کی حوصلہ افزائی کر سکے۔ اور مجھے ایسا لگتا ہے کہ خان اکیڈمی جس چیز کی تعمیر کر رہی ہے اس کے ساتھ اس کا ہم آہنگ ہے۔ اور میں، آپ کو معلوم ہے، کہ آپ ہر طالب علم میں اس صلاحیت کو کھولنا چاہتے ہیں۔ اور اس طرح یہ بالکل ایسا ہی تھا جب\nہمیں احساس ہوا کہ شاید ہم تعلیم میں واقعی ایک ڈینٹ بنا سکتے ہیں، شاید اس کا اطلاق وہاں ہو سکتا ہے۔ یہ اتنا واضح تھا کہ خان اکیڈمی کال کی پہلی بندرگاہ تھی۔ - اور تب سے، آپ جانتے ہیں، میرا اندازہ ہے کہ ہم نے مل کر کام کیا ہے، اور ظاہر ہے کہ اب GPT-4 وہاں موجود ہے، آپ کیا امید کر رہے ہیں کہ یہ ہو جائے گا؟ آپ کی طرح، آپ کیسے امید کرتے ہیں کہ تعلیمی\nدنیا اس سے فائدہ اٹھائے گی؟ مشہور طور پر جب ChatGPT سامنے آیا تو اس نے تعلیمی دنیا میں کافی تناؤ پیدا کیا۔\n لوگ ایسے تھے، اوہ،\nبچے اسے اپنے مضامین میں دھوکہ دینے\nیا اپنا ہوم ورک کرنے کے لیے استعمال کریں گے۔ اساتذہ کو\nاس بارے میں ابھی کیسے سوچنا چاہیے؟ - ہاں، مجھے لگتا ہے کہ میں یہ\nکہوں گا کہ آپ کو معلوم ہے کہ تعلیم کا ایک مخصوص ورژن ہے جو میں عام طور پر کہہ رہا ہوں، ٹھیک ہے؟ کہ مواقع ہیں، خطرات ہیں۔ اور مجھے لگتا ہے کہ یہ جاننا کہ کس طرح نیویگیٹ کیا جائے یہ واقعی اہم ہے۔ اور آپ کو\nاس تناؤ میں جھکنا پڑے گا، ٹھیک ہے؟  اس لیے، میں سمجھتا ہوں کہ یہ\nضروری ہے کہ لوگ اپنے لیے سوچنا سیکھیں، لیکن میرے خیال میں یہ بھی بہت اہم ہے کہ طلباء، آپ\nجانتے ہیں، ٹیکنالوجی سے بہترین فائدہ اٹھا سکتے ہیں اور\nہم اس ٹیکنالوجی کو بہت قابل رسائی بنا رہے ہیں اور  ان\nلوگوں کے لیے دستیاب ہے جو بصورت دیگر بہترین تعلیمی اوزار حاصل نہیں کر سکتے۔ اور اس لیے میں سمجھتا ہوں کہ، آپ کو معلوم ہے، میری امید ہے کہ ہم\nایک ایسے پلیٹ فارم کے طور پر کام کریں گے جو اساتذہ، معلمین\nاپنی پسند کے مطابق بنانے اور\nاپنے طلباء کے ساتھ کام کرنے میں مدد کرنے اور اس خلا کو پر کرنے کے قابل ہیں جو وہ نہیں کر سکتے۔ اور اس طرح، آپ جانتے ہیں، مجھے لگتا ہے کہ\nایپلی کیشنز کی قسم، میں دراصل ایک قسم کا متجسس ہوں گا، سال، آپ ان چیزوں کے طور پر کیا دیکھ رہے ہیں جن کے بارے میں آپ سب سے زیادہ پرجوش ہیں۔ - ہاں. ٹھیک ہے، آپ جانتے ہیں، ظاہر ہے، ہم اس میں بہت کچھ ڈال رہے ہیں اور ہم بہت پرجوش ہیں، آپ جانتے ہیں، ہم نے ڈیمو بھی کر دیا ہے، آپ جانتے ہیں،\nہم خانمیگو کو کیا کہتے ہیں، جو کہ بنیادی طور پر AI کا اوتار ہے۔  خان اکیڈمی پر\nکچھ بڑے اسکول اضلاع کے ساتھ، جن میں سے کچھ نے مشہور طور پر چیٹ جی پی ٹی پر پابندی لگا دی ہے۔ اور وہاں ہے، آپ جانتے ہیں، وہ ہمیں رائے دے رہے ہیں، یہ وہی ہے جو ہم چاہتے تھے۔ ہم اس ٹکنالوجی کی طاقتوں کو بروئے کار لانا چاہتے تھے،\n لیکن اس کے ارد گرد کچھ حفاظتی پٹیاں لگائیں، تاکہ یہ طلباء کے لیے نتیجہ خیز طور پر استعمال ہو، تاکہ یہ، آپ جانتے ہو، اساتذہ اس طرح\nسے دیکھ سکتے ہیں کہ وہ کیا کر رہے ہیں، کہ یہ اب تدریسی اعتبار سے درست ہے۔ اب یہ دلچسپ بات ہے کہ اس نے واقعی ایک بڑی بحث کو جنم دیا ہے جہاں لوگ ایسے ہیں، ٹھیک ہے\nاگر وہ سینڈ باکس کے اندر ہوں تو یہ بہت اچھا ہے، لیکن پھر انہیں کسی اور جگہ جانے سے کیا روکنا ہے؟ اور کوئی اور\nایک ایسی ایپلی کیشن بنانے والا ہے جو API کو کچھ کرنے کے لیے استعمال کرتا ہے، آپ جانتے ہیں، یہاں یا وہاں۔ تو وہاں، میرے خیال میں\nوہاں کچھ حقیقی سوالات ہیں۔ میرا اندازہ ہے کہ شاید میں\nاسے ایک سوال کے طور پر موڑ دوں گا، آپ سب اس کے بارے میں کس طرح سوچ رہے ہیں، کیا\n یہ\nآپ کے کلاسک ایپ اسٹورز کی طرح تھوڑا سا ہوگا جہاں اس بات کا تھوڑا\nسا ادارتی جائزہ ہوتا ہے کہ لوگ کیسے ہیں؟  API کا استعمال کرتے ہوئے یا اس کی طرح زیادہ ہونے والا ہے،\nآپ کو بتائیں، آئیے دیکھتے ہیں کہ کیا ہوتا ہے۔ آپ سب اس کے بارے میں کیسے سوچ رہے ہیں؟ اور میرا اندازہ ہے کہ ہم\nتعلیم کے بارے میں عام طور پر یا تعلیم کے بارے میں خاص طور پر یا عام طور پر بات کر سکتے ہیں۔ - جی ہاں. ٹھیک ہے، مجھے لگتا ہے کہ سچ یہ ہے\nکہ یہ ٹیکنالوجی بہت نئی ہے اور\nسیکھنے کے لیے بہت کچھ ہے، ٹھیک ہے؟ لیکن ہم اس کے بارے میں بہت سوچ رہے ہیں۔ ہم بہت زیادہ وقت یہ\nسوچنے میں صرف کرتے ہیں کہ لوگوں کو ہمارے پلیٹ فارمز پر بالکل کیسے تعمیر کرنا چاہیے،\n مشغولیت کے اصول کیا ہونے چاہئیں،\nبہت ساری معلومات حاصل کرنے کی کوشش کرتے ہیں۔ لہذا ہم معلمین کے ساتھ اور دوسرے لوگوں کے ساتھ\nاور مختلف جگہوں پر بہت زیادہ مشغول رہتے ہیں کیونکہ میں سمجھتا ہوں کہ آخر کار یہ فیصلہ کرنا ہے کہ اس قسم\nکی ٹیکنالوجی کو دنیا میں کیسے ضم کیا جائے، یہ صرف ہم پر منحصر نہیں ہونا چاہیے۔ جیسا کہ ہمیں یقینی طور پر اس کا حصہ بننے کی ضرورت ہے، اگر یہ ہماری ٹیکنالوجی ہے، لیکن ہم سمجھتے ہیں کہ ہر ایک سے وسیع ان پٹ حاصل کرنا واقعی اہم ہے۔ تو یہ دراصل ایک\nچیز ہے جو میرے خیال میں شاید واحد سب سے اہم عنصر ہے۔ اور اس لیے آپ کو ارتقاء کی توقع کرنی چاہیے، ٹھیک ہے؟ آپ کو ہم سے ڈیٹا حاصل کرنے کی توقع کرنی چاہئے اور یہ سمجھنا چاہئے کہ ارے، جیسا کہ اس خاص\nچیز نے بہت اچھا کھیلا، اس خاص چیز نے ایسا نہیں کیا، اور پھر اپنانے کا طریقہ سیکھیں۔ تو میری امید یہ ہے کہ، آپ جانتے ہیں، نمبر ایک، مجھے لگتا ہے کہ واقعی الٹا دکھانا بہت ضروری ہے، ٹھیک ہے؟ کہ مجھے لگتا ہے کہ صرف ان چیزوں کو دیکھنا آسان ہے جو غلط ہو سکتی ہیں۔ اور میں سمجھتا ہوں کہ یہ ضروری ہے کہ آپ\nاپنا سر ریت میں نہ رکھیں، لیکن جس وجہ سے ہم\nاسے پہلی جگہ بناتے ہیں، ٹھیک ہے، دراصل\nان فوائد کا احساس کرنا ہے۔ اور اس لیے میں\nخان اکیڈمی یا کسی اور کے ساتھ جو\nاس جگہ میں واقعتاً کام کرنے جا رہا ہوں، \nاضلاع کے ساتھ گہرائی میں جانا، معلمین سے بات کرنا اور واقعی یہ جاننا کہ وہ کیا چاہتے ہیں وہ یہ دیکھ کر بہت پرجوش ہوں۔  . ایک بار جب آپ کے پاس\nکسی چیز کے کام کرنے کی مثبت مثال ہے، تو \nاس کے ارد گرد معیار بنانا آسان ہے، ٹھیک ہے؟ اگر آپ کے پاس یہ بالکل بھی نہیں ہے، تو آپ صرف اندھیرے میں شوٹنگ کر رہے ہیں۔ اور ہم نے اسے پہلے ہی دیکھا ہے، آپ جانتے ہیں، آخری بار زبان کے ماڈلز کی تعیناتی کے لیے حفاظتی معیارات کے بارے میں ایک بلاگ پوسٹ دوبارہ شائع کریں۔\n اور یہ سب دو\nسال کے قابل تعیناتیوں اور ایمانداری سے بہت غلط ہونے سے آیا ہے۔ اور اس لیے میں سمجھتا ہوں کہ\n مشق سے سیکھنے کی یہ تکراری تعیناتی،\nیعنی، میرے خیال میں، واحد سب سے اہم چیز جو ہم سب ابھی کر رہے ہیں۔ - نہیں، میں مکمل طور پر متفق ہوں. واضح طور پر، آپ جانتے ہیں، ہم بہت زیادہ سرمایہ کاری کر رہے ہیں کیونکہ ہم\nعام طور پر اس بارے میں بہت پر امید ہیں کہ یہ سب کہاں جا رہا ہے۔ اور آپ جانتے ہیں، میں اس کے بارے میں کھل کر بات نہیں کر سکتا تھا\nجب میڈیا میں یہ تمام ChatGPT بحثیں چل رہی تھیں، لیکن پھر ایک بار جب ہم کامیاب ہو گئے،\nمیں کہہ رہا تھا، دیکھو، یہ، مجھے معلوم ہے کہ کچھ خوف ہے، لیکن اگر آپ  اسے صحیح چوکیوں کے ساتھ صحیح فریم ورک میں رکھیں، نہ صرف آپ ان خطرات کو کم کر سکتے ہیں، بلکہ آپ بڑے پیمانے پر پیشرفت کر سکتے ہیں، ہر طالب علم کے لیے ایک ٹیوٹر\nاور بالکل نئے طریقے متعارف کروا سکتے ہیں جو کہ\nAI کے بغیر سائنس فکشن کی طرح لگتا ہے، جیسے چیزیں۔  تاریخی شخصیت کا انٹرویو کریں، اپنی بحث کی مہارتوں کی مشق کریں۔ آپ جانتے ہیں، ہم جا سکتے ہیں، آپ\nجانتے ہیں، اساتذہ اسباق کے منصوبے بنانے میں مدد کرنے کے قابل ہیں،\nوغیرہ وغیرہ۔ آپ جانتے ہیں، ایک بحث جو\nمیں نے حال ہی میں بہت سے دوستوں کے ساتھ کیا ہے، آپ\nجانتے ہیں، جاننے والے دوست جو AI وغیرہ کے بارے میں جانتے ہیں، ہم\nاس کلاسیکی بحث میں شامل ہو رہے ہیں کہ کیا یہ ٹول\nانسانی صلاحیت کو کم کرنے یا پھیلانے والا ہے۔  انسانی صلاحیت؟ میں توسیع کی طرف ہوں۔ تو، آپ جانتے ہیں، میرے کارڈز وہیں ہیں، کہ یہ ہمیں مزید تخلیقی بنائے گا۔ کچھ عجیب طریقے سے، یہ\nحقیقت میں ہمیں مزید لکھنے پر مجبور کر سکتا ہے کیونکہ ہم مزید ایڈیٹرز بننے والے ہیں اور ہم مزید تخلیق کرنے والے ہیں۔ لیکن میں، آپ اس کے بارے میں کیسے سوچتے ہیں جب لوگ کہتے ہیں، اوہ واہ، آپ جانتے ہیں، اب لوگ صرف ایک\nکم کام کرنے والے ہیں جو انسان کرتے ہیں، وہ\nاپنی تحریری صلاحیتوں کو فروغ نہیں دے رہے ہیں، وہ تخلیقی صلاحیتوں کو فروغ نہیں دے رہے ہیں۔ کیونکہ وہ اس کے لیے مصنوعی ذہانت پر بہت زیادہ جھکاؤ رکھنے والے ہیں۔\n - جی ہاں، میرا مطلب ہے کہ میں آپ کے ساتھ ضرور ہوں سال۔ جیسے، میں سمجھتا ہوں کہ\nخالص اثر انتہائی مثبت ہو رہا ہے کہ\nمجھے لگتا ہے کہ ہم سب کو یہ AI سپر پاورز ملیں گے، ہم وہ چیزیں حاصل کر سکتے ہیں جو\nہم دوسری صورت میں نہیں کر سکتے تھے۔ مشقت دور کرنا پسند کرے گی۔ وہ تمام چیزیں جو میرے\nخیال میں یہاں ہیں، ٹھیک ہے؟ اگر افق پر نہیں۔ لیکن یقیناً یہ\nآپ کے سر کو ریت میں چپکا رہے ہوں گے کہ یہ صرف ایک ہی اثر ہے، ٹھیک ہے؟ مجھے لگتا ہے کہ یہ خالص اثر ہے اور مجھے لگتا ہے کہ یہ کافی مضبوط ہوگا۔ لیکن مجھے لگتا ہے کہ ایسی\nجگہوں کی کہانیاں ہوں گی جہاں، آپ جانتے ہو، کہ ہاں، یہ ایسے لوگوں کی طرح ہے جو کسی خاص دستکاری سے محبت کرتے تھے اور اب اس دستکاری کو کموڈیٹائز کر دیا گیا ہے، ٹھیک ہے؟ کہ داخلے میں رکاوٹ تھی۔ آپ کو ایک ہنر بنانا تھا\nاور اب کوئی بھی اسے کرسکتا ہے۔ اور ایک طرف یہ\nایک خوبصورت چیز ہے، ٹھیک ہے؟ کیونکہ یہ تمام\nلوگ ہیں جن کی تخلیقی صلاحیتوں کو اب کھولا جا سکتا ہے، ٹھیک ہے؟ وہاں ہے، آپ جانتے ہیں، سب، آپ جانتے ہیں، میں بالکل اسی طرح آپ سوچتے ہیں کہ کتنے لوگوں کے پاس اسمارٹ فون ہے؟ اور اس طرح اگر آپ ہر اس شخص\nتک رسائی حاصل کرنے کے قابل ہیں جن کے پاس اسمارٹ فون ہے بہت طاقتور AI تک اور وہ اس طریقے سے تخلیق کرنا شروع کر سکتے ہیں کہ اس سے پہلے کہ آپ کو پیشہ ورانہ سافٹ ویئر کا ایک گروپ خریدنا پسند ہو اور\nآپ کو جانا پڑے۔  اسکول اور بہت سی تربیت حاصل کریں۔ جیسا کہ آپ دیکھ سکتے ہیں کہ\nیہ دنیا کس طرح مختلف ہے۔ لیکن بہت سے طریقوں سے یہ زیادہ\nمثبت ہے، آپ جانتے ہیں، اس پر۔ لیکن مجھے لگتا ہے کہ یہ تبدیلی اور اس کے لیے تیار رہنا، جیسے، یہ ایک خوفناک چیز ہے۔ اور مجھے لگتا ہے کہ یہ وہ\nچیز ہے جسے ہمیں کھلی آنکھوں میں جانا چاہئے۔ - جی ہاں، بالکل. اور تم جانتے ہو، جب\nہم چلے گئے ہیں، جب بھی میں تم سے بات کرتا ہوں،\nتم، کبھی کبھی کہتے ہو، اوہ، اور ویسے سال،\nہم بھی اس پر کام کر رہے ہیں۔ اور پھر آپ بتائیں، مجھے دکھائیں اور میں ایسا ہی ہوں، اوہ، یہ بہت بڑی بات ہے۔ جیسے، آپ جانتے ہیں، ایسا ہی ہے، اور اور بھی بہت کچھ ہے۔ ہمیں صرف اس بات چیت کو آگے بڑھائیں، آپ جانتے ہیں،\nلوگوں کے لیے ایک تصویر پینٹ کرنا جیسے کہ کیا ہو رہا ہے اور\nآپ اس کے بارے میں زیادہ سے زیادہ بات کر سکتے ہیں اور آپ کے خیال میں اس کے کیا مضمرات ہیں اور آپ ان میں سے کسی ایک سمت پر کس طرح توجہ مرکوز کرنے کی کوشش کر رہے ہیں یا  ایک اور - ہاں، اچھی طرح سے دیکھو، مجھے لگتا ہے کہ\nانتہائی اعلیٰ سطح پر، جیسے کہ ہم واقعی\nAGI کے اس رفتار کے بارے میں سنجیدہ ہیں۔ جیسا کہ ہم سوچتے ہیں کہ یہ وہ راستہ ہے جس پر معاشرہ چل رہا ہے، دنیا چل رہی ہے۔ میرے خیال میں یہ ایک ایسا راستہ ہے جس پر\nہم طویل عرصے سے چل رہے ہیں۔ اگر آپ ان تمام منحنی خطوط کو دیکھتے ہیں اور آپ جانتے ہیں، مجھے لگتا ہے کہ ہم نے\nمشعل کو بہت سے طریقوں سے اٹھایا ہے اور ہم محسوس کرتے ہیں کہ یہ\nہماری اہم ذمہ داری ہے کہ ہم اسے نہ صرف بنائیں،\nبلکہ اس کی تعمیر کریں، ٹھیک ہے؟ اور قلیل مدتی طور پر، مجھے لگتا ہے کہ آپ\nایسی چیزیں دیکھتے ہیں، آپ جانتے ہیں، GPD 4 میں وژن ان پٹ ہیں۔ یہ وہ چیز ہے جسے\nہم اب بھی صرف ایک ساتھی کے ساتھ چلا رہے ہیں۔ لیکن مجھے لگتا ہے کہ یہ\nبھی استعمال کے لحاظ سے ایک نیا مرحلہ فعل ہوگا، ٹھیک ہے؟ کہ آپ دستاویزات پیش کرنے کے قابل ہو جائیں گے، اگر آپ کے پاس کوئی خاکہ ہے\nجو کہ خان اکیڈمی کے تعلیمی نصاب کا حصہ ہے، اور\n طلباء کے سوال کے ساتھ اس خاکہ کو سمجھ سکیں گے۔\nاس کے بارے میں اہم ہے. آپ ایسا کر سکیں گے۔ اور اس لیے مجھے لگتا ہے کہ ہم\n \nبہت سے طریقوں سے رسائی کو کھولنے جا رہے ہیں، آپ جانتے ہیں کہ اس چیز کو تیز،\nسستا، زیادہ قابل رسائی بنا کر چلایا جائے گا۔ یہ ہمارے لیے ہمیشہ ایک بڑا فوکس ہوتا ہے۔ اور واقعی بہتری کی کوشش کر رہے ہیں۔ جیسا کہ مجھے لگتا ہے کہ جس چیز کو\nہم ابھی بہت سارے طریقوں سے کھو رہے ہیں وہ\nنئے آئیڈیاز پیدا کرنے کے قابل ہے، ٹھیک ہے؟ مشکل مسائل کو حل کرنے کے قابل ہونے کی وجہ سے اور ان سب کے بارے میں جو ہم سوچ رہے ہیں، ہم تلاش کر رہے ہیں، اور آپ جانتے ہیں، ایک بار پھر، ہماری طرح کی حفاظت کی پہلی توجہ کے ساتھ ایسا کرنا۔\n - ہاں، ٹھیک ہے مجھے گریگ کہنا پڑے گا، آپ جانتے ہیں، وقت گزارنے اور ہمیں اس سفر پر لانے کے لیے بہت بہت شکریہ کیونکہ ایسا محسوس ہوتا ہے کہ\nہم سائنس فکشن کی کتاب میں رہ رہے ہیں اور یہ ان میں سے کوئی ایک اپنی\nمہم جوئی کا انتخاب ہے۔  سائنس فکشن کی کتابیں جہاں یہ مختلف سمتوں میں جا سکتی ہیں، لیکن مجھے لگتا ہے کہ جب تک\nکافی لوگ اس بارے میں سوچ رہے ہیں کہ ہم کس طرح مواقع اور فوائد کو زیادہ سے زیادہ استعمال کرتے ہیں\n اور ممکنہ حد تک زیادہ سے زیادہ خطرات کو کم کرتے ہیں، میں ہوں، اور ایسا لگتا ہے کہ آپ بھی ہم ہیں۔  اس کی وجہ سے دنیا کیسی ہو سکتی ہے اس کے بارے میں بہت پرجوش۔ \n - میں بھی ہوں، ہاں، یہ بہت اچھی بات چیت تھی۔ - بہت اچھا، شامل ہونے کا شکریہ۔ - جی ہاں، آپ کا شکریہ.",
    "t_spanish": "- Hola a todos,\naquí Sal, de Khan Academy, y como algunos de ustedes saben,\npubliqué mi segundo libro, \"Palabras nuevas y valientes sobre el futuro de la IA en la educación y el trabajo\". Está disponible en cualquier lugar donde\npuedas comprar tus libros, pero como parte de la investigación para ese libro, hice algunas entrevistas con\npersonas fascinantes, que estás a punto de ver. Hoy tenemos a Greg Brockman. Estoy muy emocionado de tenerte aquí, Greg. Para aquellos de ustedes que no lo saben, Greg es el cofundador, presidente y presidente de una organización de la que algunas personas hablan\nestos días llamada Open AI. Y nosotros, en Khan Academy, también\nhemos hecho un poco con OpenAI. Y esto es muy emocionante porque este es el\ncomienzo de un nuevo podcast, una nueva transmisión en vivo, algo nuevo que estamos haciendo\nllamado Brave New Words, que también es un libro en el que\nestamos trabajando. Greg, muchas gracias por acompañarnos. - Gracias por tenerme. - Así que comencemos, asegurándonos de que todos los que miran y escuchan tengan un entendimiento compartido. Cuéntanos un poco sobre Open AI y cómo decidiste iniciarlo y tal vez un poco de hacia\ndónde ha ido desde entonces. - Sí, entonces, ya sabes, para mí, la idea de la IA me entusiasmó por primera vez cuando leí el artículo de Alan Turing de 1950 sobre la prueba de Turing, el\ncual, ¿has leído Sal? - Sabes, no he leído el periódico. Estoy muy familiarizado con él, pero en realidad no leí el periódico. - Bueno. Así que recomiendo leerlo\nporque, ya sabes, la primera mitad trata\nsobre la prueba de Turing, pero la segunda mitad trata sobre cómo vas a resolverla. Y él dijo, mira, nunca programarás\nuna respuesta para esto. Es demasiado difícil. Pero se podría construir una\nmáquina que pudiera aprender. - Y solo para hacer una pausa,\npara aquellos que no saben, ¿ qué fue la prueba de Turing? Sólo para asegurarnos de que\ntodos estén en la misma página. - Sí, la prueba de Turing es la\nidea de ¿podrías distinguir entre una máquina y una persona\nsi tienes un juez que habla con una persona, habla con una máquina, y que si son\nindistinguibles, podrías decir que esa máquina es realmente?  inteligente. Y entonces, nuevamente, te tiene que gustar\npoder no solo, ya sabes, charlar,\ntienes que poder, en su artículo dice, está bien, como si el juez hiciera preguntas sobre ajedrez y tú tuvieras que responder ajedrez.  preguntas. Y entonces te das cuenta de que el\nlenguaje realmente captura gran parte de la experiencia humana y mucho de lo que\nsignifica ser inteligente. Y\ncreo que uno de mis cofundadores dice que Turing estaba de gira por una razón. Sabes, él es realmente brillante. Una de sus grandes ideas es: mira, tendrás que aprender una respuesta. Tendrás que construir una máquina que pueda entender\ncómo realizar tareas.  No podemos. Y ese fue para mí el\nmomento en que todo encajó. Pero, por supuesto, esto fue como en\n2008, así que nada funcionó en la IA y no fue hasta otros siete años que, mirando desde\nafuera el aprendizaje profundo y el hecho de que las computadoras se\nhabían vuelto lo suficientemente rápidas, que ahora eran comercialmente útiles, que empezamos a darnos cuenta de que, mira, tal vez realmente haya\nuna posibilidad de hacer realidad este sueño. Y ya sabes, otros y yo nos unimos porque queríamos ver si\npodíamos dirigir la tecnología de inteligencia artificial de manera positiva. Quería ver si\nrealmente podíamos construir el tipo de máquina de la que había hablado Turing, una inteligencia a nivel humano,\nlo que llamamos AGI, y que eso fuera algo\nque beneficiara a toda la humanidad. Esa es la misión de OpenAI. Entonces impulsamos la tecnología. Realmente queremos que sea\nbeneficioso, seguro y distribuir esos beneficios a todos.  Creo que hemos estado trabajando en ello\ndurante ocho años. Y en ese tiempo, seguimos haciendo la misma actividad, simplemente construimos una red neuronal más grande, la hacemos más capaz, la hacemos más alineada, la hacemos más segura. Y en los últimos dos años, también hemos comenzado a implementarlo\ny hacerlo útil. Y eso es lo que creo que me resulta tan interesante de esta tecnología. No es como una fusión en la que o lo tienes o no lo tienes. Es en cada paso del camino que\nrealmente se puede tener un impacto y\nempezar a beneficiar a las personas. Y creo que eso es bueno y, ya sabes, puedes ver los beneficios\nde lo que has creado y, de hecho, aprender cómo\nmitigar todas las desventajas. Entonces creo que esa es\nla etapa en la que nos encontramos. - Sí, hay mucho en eso. Quiero decir, ya sabes, parece que, según cuando\nestás trabajando en cosas de IA, soy un poco más de 10 años mayor o un poco más que\neso, mayor que tú. Pero ya sabes, a mediados de los noventa, cuando estaba en la universidad, y ya sabes, estaba trabajando con algunos\nde los primeros pioneros y algunos de ellos eran mis profesores y era lo mismo. Estaba muy entusiasmado con la\ninteligencia artificial. Leí ciencia ficción y pensé, oh, esto\nllevará una eternidad, si es que alguna vez sucede. E incluso en lo que usted dice, usted experimentó lo mismo\nunos 10 o 12 años después. Y luego, incluso cuando estaban\npensando en iniciar OpenAI, esto, ya saben,\nlo que mencionaron AGI, Inteligencia General Artificial, creo que muchas personas reflexivas,\nsi soy honesto, incluso yo mismo, y tiendo a ser bastante\noptimista al respecto.  cosas, hubiera pensado que eso es\nun poco delirante, comenzar a\ntrabajar ahora en, ya sabes, ni siquiera un laboratorio de investigación. Quiero decir, supongo que es una\nespecie de laboratorio de investigación, pero iniciar una\norganización que tenga.  ¿ Pensaste que eran\npersonas que te decían eso?  ¿ Cómo decidiste hacerlo de todos modos? - Oh sí. Quiero decir que recibimos muchos\ncomentarios muy, muy negativos de la comunidad. Y lo que realmente\nencontré más interesante fue que estábamos hablando de\nseguridad de la IA antes de que fuera genial. Y, de hecho, recuerdo haber\nhablado con un candidato que trabajaba en un gran laboratorio de IA y que dijo: \"Sí, creo que la seguridad AGI es el problema más importante. Creo que realmente importa. Pero si alguna vez me citan sobre\neso,  Lo negaré todo\". Y creo que eso es lo que nos diferencia: estábamos realmente\ndispuestos a pensar hacia dónde se dirige y actuar en consecuencia. No estamos solos. Hay otras personas en el campo, otros pioneros que han estado\nimpulsando este tipo de tecnología y, ya sabes, también han sido, creo,\nmuy visionarios en términos de pensamiento, ya sabes,\nincluso muchos años por delante de nosotros. para empezar con este problema. Pero creo que tal vez, ya sabes, no sé si es\nsolo algo en nuestro ADN o si es algo así como, ya\nsabes, para mí personalmente, sentí\ncomo si hubiera pasado cinco años construyendo una tecnología.  compañía. Estaba listo para involucrarme realmente\nen un problema en el que estaba listo para trabajar por el resto de mi vida. Y fue tan claro para mí que si pudiera\nprofundizar un poco, incluso si estamos hablando de 300 años después y aparece AGI, valdría la pena.  ¿ Bien? Y, ya sabes, existe la posibilidad de que sea incluso antes. Y entonces creo que es\namable el encuadre es la línea de tiempo, puedes discutirlo,\npuedes debatirlo, puedes hablar sobre estas cosas, pero fundamentalmente\napuntando al impacto de la tecnología más importante que los humanos jamás crearán. Como si eso fuera algo que puedo respaldar. - Y lo que es notable, y supongo que esto no es una\nnovedad para mucha gente porque OpenAI ha aparecido\nmucho en las noticias últimamente es, ya sabes, tienes estos\nmodelos GPT, estos, ya sabes, transformadores generativos preentrenados.  ,\nesta tecnología es, ya sabes, una especie de redes neuronales, que han estado en la\ncomunidad de IA durante algún tiempo, y todos tenían GPT-1, GPT-2, la gente decía, oh, esto es interesante, puede escribir  , pero, ya sabes, realmente no tiene un buen manejo del conocimiento,\nGPT-3 aún mejor. Y luego aparece ChatGPT\n, es una interfaz, que empieza a sorprender\nun poco a la gente. Y luego, obviamente,\nanunciamos con todos ustedes que hemos estado trabajando\njuntos en GPT-4, en su uso en Khan Academy, pero obviamente todos ustedes han estado haciendo todo el trabajo para desarrollarlo. Esta noción de AGI,\nInteligencia General Artificial, ya no parece tan descabellada.  Ya sabes, incluso algo de\nlo que creo que mucha gente ha conseguido que haga GPT-4 empieza a sentirse un poco así. Supongo que mi primera pregunta es: ¿ qué creen que están\nhaciendo para llegar a este punto en el que\nhay muchísimas personas trabajando en el campo, muchas organizaciones más grandes\ncon más recursos?  ¿ Crees que es algo que\nestás haciendo diferente o cómo lo estás abordando o? Sí, ¿qué crees que es especial? - Sí, creo que es una pregunta correcta. Quiero decir, creo que somos parte de una tendencia mucho más amplia, ¿verdad? Es como una historia mucho más amplia, ¿verdad?  Si miras hacia atrás en todas las curvas de cálculo, durante 70 años tuvimos\neste crecimiento exponencial y ya sabes, en el año 2000\nRay Kurzweil decía, oye, solo mira el cálculo, eso\nte dirá lo que será posible. Ése es el combustible para el progreso. Y todos pensaron que estaba loco. Y ahora creo que básicamente\npiensan que tiene razón. Y creo que, ya sabes,\nsi piensas en la cantidad de ingeniería que\nimplica poder ofrecer algo como GPT-4, desde la infraestructura informática real\nhasta todos los conjuntos de datos y herramientas que utilizamos, eso es realmente  este enorme esfuerzo de la humanidad en muchos sentidos. Pero más o menos específicamente,\nya sabes, logramos ejecutarlo porque\nreunimos a personas con experiencia en investigación\ny en ingeniería. Y creo que eso es algo muy singular, ¿verdad? Y creo que, ya sabes,\nla seguridad es una parte fundamental de eso que viene desde\ntodos los diferentes ángulos. Es, ya sabes, tanto en la práctica como en la teoría,\npensar en cómo se comportarán estos sistemas, cómo\nirán bien y mal. Pero sí, creo que lo\nque fue tan interesante para mí cuando empezamos fue observar todos los demás\nlaboratorios, y realmente se puede ver que provienen de\nuna experiencia típicamente de investigación. Y entonces tienes a estos ingenieros de investigación a quienes se les dice qué hacer, y los científicos investigadores\npueden hacer lo que quieran. Y piensas, así no\nparece como vas a construir un sistema que funcione. Parece una excelente manera\nde obtener un montón de citas, pero si realmente quieres tener un impacto y desarrollar algo, solo necesitas estructurar la organización de manera diferente. Y es difícil,\nparece fácil en el papel, pero hay formas muy conflictivas de pensar sobre las cosas si\ntienes una formación muy práctica versus si tienes una formación más académica. Y de alguna manera tenemos que apoyarnos en ellos. Y creo que hemos\nresuelto versiones más sofisticadas de este tipo\nde mentalidades diferentes, diferentes orígenes y\nproblemas, como muchas, muchas veces. Y nunca lo resuelves por completo. Pasas a una\nversión más sofisticada. Así que creo que se trata de\ninclinarse hacia la incomodidad, inclinarse hacia las partes difíciles. - No, tengo tantas\npreguntas porque creo que, ya\nsabes, hay algo único que todos ustedes deben estar haciendo. Ustedes no son una organización tan grande y definitivamente, supongo, están por encima de su peso. Pero una de las cosas de las que\nhas hablado mucho, y esta fue incluso una de\nlas razones para iniciar OpenAI como una organización sin fines de lucro, y\nhablaremos un poco sobre cómo han evolucionado las cosas desde entonces, pero  Sigues mencionando la seguridad y, ya sabes, la IA es emocionante y tal vez incluso aterradora para algunas personas. Todos hemos leído ciencia ficción tanto emocionante como distópica. Cuando hablas de seguridad, ¿de qué estás hablando?  ¿ Cuáles son los temores reales por los que\nla gente debería preocuparse y poner restricciones y cuáles son los que\ntal vez no estén tan justificados? - Sí, creo que ha\nhabido una larga historia de pensamiento sobre la seguridad de la IA, ¿verdad? Y creo que hay algunos\nanteriores, ya sabes, que se remontan a los años cincuenta o sesenta. Puedes encontrar gente como Arthur\nC. Clark hablando de esto, de tener una máquina inteligente. Y ya sabes, lo que distingue a los humanos es el hecho de que somos inteligentes. Y entonces es algo nuevo, ¿verdad? Toda esta idea.  Por eso creo que deberíamos abordarlo con partes iguales de entusiasmo\npor lo que se puede lograr y precaución sobre dónde podríamos equivocarnos. Así que creo que es\nfundamentalmente correcto tener estos sentimientos encontrados y al mismo tiempo\nsorprenderse por cualquier cosa nueva, pero también preguntar hacia dónde va esto y dónde está esto en particular.  ¿ Dónde podrían estar los peligros? Creo que esa es la única forma en que\npodemos navegar correctamente por el espacio. Pero creo que otra cosa que ha sido muy interesante\nes lo sorprendente que parece ser la IA y cómo se desarrolla. Como piensas, en los\naños noventa todos pensaban que, oh, si simplemente resuelves ajedrez,\neso te llevará a AGI. Y, de hecho, el ajedrez fue lo primero que\nresolvimos en muchos sentidos, y en realidad no fue más allá. Y creo que he visto lo mismo\nen cuanto al pensamiento de seguridad, ¿verdad? Que si lo piensas\ncomo, oh, ya sabes, algo que podría haberse construido, una dirección que creo que era posible, era construir estos agentes que tienen que sobrevivir, replicarse y evolucionar de alguna manera.  una especie de simulación complicada de múltiples agentes. Eso suena realmente aterrador, ¿verdad? Incluso saber de qué\nson capaces esos agentes. Y ya sabes, para poder confiar en ellos, tienes que resolver algunos\nproblemas realmente difíciles.  Por lo tanto, se requiere mucho esfuerzo\npara pensar en cómo diseñar una función de recompensa que escriba de manera muy\nespecífica y que no tenga cuidado con lo que desea. Y entonces se ha pensado mucho en ese tipo\nde formas de resolver problemas, pero el paradigma GPT\n, nadie lo vio venir, es totalmente diferente de lo que se esperaría desde\nuna perspectiva de seguridad. Entonces, para mí, la lección realmente es esta: incluso saber cómo\nmanejar la tecnología y descubrir para qué\npodría usarse y cómo\ndirigirla en la manera correcta. No es que haya necesariamente\nun límite para la previsión, pero creo que tenemos un historial de confiar demasiado en las cosas equivocadas. Entonces, ya sabes, un ejemplo en el que puedes ver una cabeza es\nsi observas, por ejemplo, el aprendizaje por refuerzo a\npartir de las preferencias humanas. Y esto es lo que usamos para ajustar el\ncomportamiento de estos modelos. Y eso es algo que es\nmuy diferente de, digamos, GPT-3, donde lanzamos el modelo después de simplemente entrenarlo en\nel conjunto de datos base para GPT-4, donde realmente\npodemos ajustarlo y elegir los valores\nque el  exhibiciones modelo. Y de hecho comenzamos a desarrollar esa tecnología en 2017, antes de que\nexistiera cualquiera de estos modelos.  Por eso creo que se\npuede ver un poco más hacia el futuro. Deberías pensar en cómo se van a\nutilizar, asegurándote de que estén alineados con lo que el operador quiere, ya sabes, como sea que lo esté el usuario. Que no se pueden utilizar si alguien quiere hacer algo, pero la sociedad tiene una\nsociedad que es ilegal o dañina para otra persona,\ndebería haber algunos límites. Y luego también creo que\nhay efectos en el ecosistema donde, de alguna manera,\npuedes imaginar que las IA, todas hacen lo que se les\ndice que hagan localmente, pero de alguna manera eso se suma a un mundo peor.  Por eso creo que vamos a\ntener que enfrentarnos a una serie de riesgos cada vez mayores a medida que pasa el tiempo. Ya sabes,\nde alguna manera nos hemos graduado en el tipo de riesgos de estos modelos. Para GPT-3, creo que estábamos realmente preocupados por la desinformación, pero cuando realmente lo analizamos, vimos que la gente realmente\nsolo quería generar, que el vector de abuso más común\nera generar anuncios médicos para varios medicamentos. Y creo que con GPT-4,\ntenemos un nuevo tipo de clase de riesgos y creo que en el futuro tendremos nuevas\nclases de beneficios y riesgos que van de la mano. - Entonces, ya sabes, obviamente\nuna de las cosas interesantes sobre\nnosotros dos hablando en nuestras organizaciones es que ustedes se comunicaron con nosotros hace seis meses, cuando\nestaban empezando a entender la situación.  Primera versión de GPT-4. Y supongo que una pregunta que\ntengo es, ya sabes, ¿ por qué nos contactaste en ese entonces? - Sí, bueno, para mí personalmente,\nsiempre he sentido que una de las motivaciones para\nconstruir sistemas de IA, para intentar construir AGI, para conseguirles a todos un tutor personal, como yo personalmente, creo que\nmucha gente tiene una historia de eso.  un maestro que\nrealmente los entendió, que los ayudó a lograr y\nentusiasmarse con una materia. Y imagínense lo que\npasaría si todos tuvieran acceso a un tutor las 24 horas del día, los 7 días de la semana, que realmente pudiera comprenderlos\ny motivarlos. Y siento que eso está muy alineado con lo que Khan Academy está construyendo. Y yo, ya sabes, el potencial que quieres desbloquear en cada estudiante. Y fue como cuando\nnos dimos cuenta de que tal vez realmente pudiéramos hacer mella en la educación, tal vez esto podría aplicarse allí. Estaba tan claro que Khan Academy era el primer puerto de escala. - Y desde entonces, ya sabes, supongo que a medida que hemos trabajado juntos y, obviamente, ahora que el GPT-4 está disponible, ¿en qué esperas que se convierta esto?  ¿ Cómo espera que el\nmundo de la educación aproveche esto?  Es famoso que cuando salió ChatGPT, causó mucho estrés\nen el mundo de la educación. La gente decía, oh,\nlos niños van a usar esto para hacer trampa en sus ensayos\no hacer sus tareas.  ¿ Cómo deberían\npensar los educadores sobre esto en este momento? - Sí, creo que\ndiría que hay una especie de versión educativa específica de lo que he estado diciendo en general, ¿verdad? Que hay oportunidades, hay riesgos. Y creo que descubrir cómo navegar eso es realmente importante. Y tienes que apoyarte\nen esa tensión, ¿verdad? Entonces, creo que es\nimportante que las personas aprendan a pensar por sí mismas, pero creo que también es muy importante que los estudiantes puedan, ya\nsabes, sacar lo mejor de la tecnología y que\nestamos haciendo que esta tecnología sea muy accesible y  disponible\npara personas que de otro modo no podrían obtener excelentes herramientas educativas. Entonces creo que mi esperanza es que sirvamos como\nuna plataforma que los maestros y educadores puedan\nmoldear a su gusto y ayudar a\ntrabajar con sus estudiantes y llenar los vacíos que no pueden. Entonces, ya sabes, creo que\nlos tipos de aplicaciones, en realidad tendría curiosidad, Sal, cuáles has estado viendo como las que más te entusiasman. - Sí. Bueno, sabes, obviamente, hemos estado poniendo mucho en esto y estamos muy entusiasmados, ya sabes, incluso hemos hecho una demostración, ya sabes,\nde lo que llamamos Khanmigo, que es esencialmente la encarnación de la IA.  en Khan Academy con\nalgunos distritos escolares grandes, algunos de los cuales han prohibido ChatGPT. Y, ya sabes, nos están dando su opinión, esto es lo que queríamos. Queríamos aprovechar los\npoderes de esta tecnología, pero pusimos algunas barreras a su alrededor, para que los estudiantes la utilicen de manera productiva, para que los profesores puedan\nver lo que están haciendo, que ahora es pedagógicamente sólido. Ahora bien, es interesante que haya creado un debate realmente grande en el que la gente dice, bueno,\nesto es genial si están dentro de la zona de pruebas, pero entonces, ¿qué les impide ir a otro lugar? Y alguien más\ncreará una aplicación que use la API para hacer algo, ya sabes, aquí o allá. Entonces, creo que hay\nalgunas preguntas reales ahí. Supongo que tal vez\ncambiaré eso como una pregunta: ¿ cómo piensan ustedes\nsobre esto en términos de si será un poco\ncomo las tiendas de aplicaciones clásicas donde hay una\npequeña revisión editorial de cómo es la gente?  usando la API o va a ser más\nasí, háganoslo saber, veamos qué pasa.  ¿ Cómo están pensando en esto? Y supongo que podríamos hablar\nde educación en general o de educación en particular o en general. - Sí. Bueno, creo que la verdad\nes que esta tecnología es muy nueva y hay\nmucho que aprender, ¿no? Pero lo pensamos mucho. Pasamos mucho tiempo\npensando exactamente en cómo la gente debería construir en\nnuestras plataformas, cuáles deberían ser las reglas de participación,\ntratando de obtener muchas aportaciones. Así que nos involucramos mucho con los educadores y con otras personas\ny en diversos espacios porque creo que, en última instancia, la decisión de cómo integrar este tipo\nde tecnología en el mundo no debería depender solo de nosotros. Seguro que necesitamos ser parte de eso, si se trata de nuestra tecnología, pero creemos que es muy importante obtener amplias aportaciones de todos.  En realidad,\ncreo que ese es el factor más importante. Entonces deberías esperar evolución, ¿verdad? Deberíamos esperar que obtengamos datos y nos demos cuenta de que esto en particular\nfuncionó muy bien y esto en particular no, y luego aprender a adaptarnos. Así que mi esperanza es que, ya sabes, número uno, creo que es muy importante mostrar realmente las ventajas, ¿verdad? Creo que es fácil ver sólo las cosas que pueden salir mal. Y creo que es importante\nno esconder la cabeza en la arena, pero la razón por la que construimos\nesto en primer lugar es para\nobtener esos beneficios. Y entonces, lo que realmente me emociona\nver es con Khan Academy o cualquier otra persona que vaya\na construir en este espacio para realmente involucrarse,\nprofundizar en los distritos, hablar con los educadores y realmente descubrir cuál es la configuración exacta que quieren.  . Una vez que tienes un\nejemplo positivo de algo que funciona, es fácil crear\nestándares en torno a ello, ¿verdad? Si no tienes eso en absoluto, entonces simplemente estás disparando en la oscuridad. Y ya hemos visto esto, ya sabes, en la última publicación de un blog\nsobre estándares de seguridad para implementar modelos de lenguaje. Y todo eso provino de dos\naños de implementaciones y, honestamente, de equivocarse mucho.  Por eso creo que este\ndespliegue iterativo de aprendizaje a partir de la práctica\nes, creo, lo más importante que todos podemos hacer en este momento. - No, estoy completamente de acuerdo. Claramente, estamos invirtiendo tanto porque en\ngeneral somos muy optimistas sobre hacia dónde va todo esto. Y sabes, no podía hablar abiertamente sobre\neso cuando había todos estos debates sobre ChatGPT en los medios, pero una vez que pudimos,\ndije, mira, esto, sé que hay algunos temores, pero si  Ponlo en el marco correcto con las barreras adecuadas, no solo puedes mitigar esos riesgos, sino que también puedes tener avances masivos, un tutor para cada estudiante\ne introducir modalidades completamente nuevas que habrían parecido\nciencia ficción sin IA, cosas como  entrevista a una figura histórica, practica tus habilidades de debate.  Ya sabes, podríamos ir, ya\nsabes, que los maestros puedan ayudar a crear\nplanes de lecciones, etcétera, etcétera.  Ya sabes, un debate que\nhe estado teniendo con muchos amigos últimamente, ya\nsabes, amigos conocedores que saben sobre IA, etcétera, hemos estado entrando en\neste debate clásico sobre si la herramienta\ndisminuirá la capacidad humana o se expandirá.  capacidad humana? Estoy del lado de expandir. Entonces, ya sabes, ahí es donde están mis cartas, que nos hará más creativos. De alguna manera extraña, podría\nhacernos escribir más porque seremos más editores y crearemos más. Pero yo, ¿cómo piensas en eso cuando la gente dice, oh vaya, ya sabes, ahora la gente será una\ncosa menos que los humanos, no desarrollarán\nsus habilidades de escritura, no desarrollarán la creatividad ?  Porque simplemente se apoyarán mucho más en la\ninteligencia artificial. - Sí, quiero decir que definitivamente estoy contigo Sal. Creo que\nel efecto neto será extremadamente positivo y\ncreo que todos vamos a obtener estos superpoderes de IA, podemos lograr cosas que\nde otra manera no podríamos. El trabajo pesado se esfumará. Todas esas cosas\ncreo que están aquí, ¿verdad? Si no en el horizonte. Pero, por supuesto, sería\nesconder la cabeza en la arena decir que ese es sólo el único efecto, ¿verdad? Creo que ese es el efecto neto y creo que será bastante fuerte. Pero creo que\nhabrá anécdotas de lugares donde, ya sabes, sí, es como si la gente amaba un oficio en particular y ahora ese oficio se mercantiliza, ¿verdad? Que había una barrera de entrada. Había que desarrollar una habilidad\ny ahora cualquiera puede hacerlo. Y por un lado es\nalgo bonito, ¿no? Porque hay todas estas\npersonas cuya creatividad ahora se puede desbloquear, ¿verdad? Hay, ya sabes, todo el mundo, ya sabes, yo. Simplemente piensas en ¿cuántas personas tienen un teléfono inteligente? Entonces, si puedes\ndarle acceso a todos los que tienen un teléfono inteligente a una IA muy poderosa y pueden comenzar a crear de una manera que antes tendrías que comprar un montón de software profesional y\ntendrías que ir a  escuela y recibir mucha capacitación. Como puedes ver cómo\nese mundo es diferente. Pero en muchos sentidos es más\npositivo, ya sabes, en eso. Pero creo que este cambio y estar preparado para eso es algo aterrador. Y creo que eso es\nalgo en lo que deberíamos mirar con los ojos bien abiertos. - Si absolutamente. Y sabes, justo en\nel tiempo que nos queda, cada vez que hablo contigo, a\nveces dices, oh, y por cierto, Sal,\ntambién estamos trabajando en esto. Y luego dices, muéstramelo y yo digo, oh, eso es gran cosa. Ya sabes, es como, y hay más. Complete esta conversación simplemente, ya sabes, pintando un\ncuadro para la gente sobre lo que está por venir, tanto\ncomo puedan hablar sobre ello y cuáles creen que son las implicaciones y cómo están tratando de concentrarse en una de esas direcciones o  otro. - Sí, bueno, mira, creo que\nen el nivel más alto, realmente nos tomamos en serio\nesta trayectoria hacia AGI. Pensamos que esa es la trayectoria en la que se encuentra la sociedad, el mundo. Creo que es un camino que\nllevamos haciendo desde hace mucho tiempo. Si miras todas estas curvas y sabes, creo que hemos\ntomado la antorcha de muchas maneras y sentimos que es\nnuestra principal responsabilidad no solo construirla,\nsino construirla, ¿verdad? Y a corto plazo, creo que se ven\ncosas como, ya sabes, GPD 4 tiene entradas de visión. Eso es algo que\ntodavía estamos probando con un socio. Pero creo que esa\ntambién será una nueva función en términos de usabilidad, ¿verdad? Podrás presentar documentos, podrás, ya sabes, si tienes un diagrama\nque sea parte del plan de estudios educativo de Khan Academy y comprender\nese diagrama junto con las preguntas de los estudiantes.\nal respecto es importante. Podrás hacer eso.  Por eso creo que vamos a\nabrir la accesibilidad de\nmuchas maneras, ya sabes, haciendo que esto funcione más rápido,\nmás barato y más accesible. Ese es siempre un gran enfoque para nosotros. Y realmente tratando de mejorar. Creo que lo que\nnos falta en este momento en muchos sentidos es poder\ngenerar nuevas ideas, ¿verdad? Ser capaz de resolver problemas más difíciles y todo eso en lo que estamos pensando, estamos explorando y, ya sabes, nuevamente, haciéndolo con nuestro tipo\nde enfoque en la seguridad. - Sí, bueno, debo decir Greg, ya sabes, muchas gracias por dedicar el tiempo y llevarnos a este viaje porque realmente se siente como si\nestuviéramos viviendo en un libro de ciencia ficción y es como uno de esos, elige tu propia\naventura.  libros de ciencia ficción donde puede ir en diferentes direcciones, pero creo que mientras haya\nsuficiente gente pensando en cómo maximizar las\noportunidades y los beneficios y mitigar tantos riesgos como sea posible, lo haré, y parece que usted también lo haremos.  Estoy muy entusiasmado con cómo podría ser el mundo\ndebido a esto. - Yo también, sí, fue genial charlar. - Genial, gracias por unirte. - Sí, gracias.",
    "t_arabic": "- مرحبًا جميعًا، سال\nهنا، من أكاديمية خان، وكما يعلم البعض منكم، فقد\nأصدرت كتابي الثاني، \"كلمات جديدة شجاعة حول مستقبل الذكاء الاصطناعي في التعليم والعمل.\" إنه متاح أينما\nيمكنك شراء كتبك، ولكن كجزء من البحث لهذا الكتاب، أجريت بعض المقابلات مع\nبعض الأشخاص الرائعين، والتي أنت على وشك مشاهدتها. إذن لدينا اليوم جريج بروكمان. أنا متحمس جدًا لوجودك هنا، جريج. بالنسبة لأولئك منكم الذين لا يعرفون، جريج هو المؤسس المشارك ورئيس مجلس الإدارة والرئيس لمنظمة يتحدث عنها بعض الأشخاص\nهذه الأيام تسمى Open AI. ونحن، في أكاديمية خان،\nقمنا ببعض الشيء مع OpenAI أيضًا. وهذا مثير للغاية لأن هذه\nبداية لبودكاست جديد، بث مباشر جديد، شيء جديد نقوم به\nيسمى \"كلمات جديدة شجاعة\"، وهو أيضًا كتاب\nنعمل عليه أيضًا. لذا جريج، شكرًا جزيلاً لانضمامك إلينا. - أشكركم على استضافتي. - لذلك دعونا نبدأ، تأكد من أن كل من يشاهد ويستمع لديه فهم مشترك. أخبرنا قليلاً عن Open AI وكيف قررت أن تبدأه وربما القليل عن\nالمكان الذي وصل إليه منذ ذلك الحين. - نعم، بالنسبة لي، كنت متحمسًا لفكرة الذكاء الاصطناعي لأول مرة عندما قرأت ورقة بحثية لآلان تورينج عام 1950 حول اختبار تورينج، هل\nقرأتها لسال؟ - كما تعلم، أنا لم أقرأ الورقة. أنا على دراية بالأمر، لكني لا أقرأ الجريدة فعليًا. - تمام. لذا أنصح\nبقراءته لأنه، كما تعلمون، النصف الأول يدور\nحول اختبار تورينج، لكن النصف الثاني يدور حول كيفية حل المشكلة؟ وقال، انظر، لن تتمكن أبدًا من برمجة\nإجابة لهذا الشيء. إنه أمر صعب للغاية. ولكن يمكنك بناء\nآلة يمكنها التعلم. - وللتوقف قليلاً،\nبالنسبة للأشخاص الذين لا يعرفون، ما هو اختبار تورينج؟ فقط للتأكد من أن\nالجميع على نفس الصفحة. - نعم، اختبار تورينج هو\nفكرة هل يمكنك التمييز بين الآلة والشخص\nمن خلال وجود قاض يتحدث إلى شخص، ويتحدث إلى آلة، وإذا\nلم يكن من الممكن التمييز بينهما، فيمكنك القول أن تلك الآلة هي حقًا  ذكي.  وهكذا، مرة أخرى، عليك أن تحب أن تكون\nقادرًا ليس فقط على الدردشة، بل يجب أن\nتكون قادرًا على ذلك، كما يقول في ورقته، حسنًا، مثل القاضي الذي يطرح أسئلة حول الشطرنج وعليك الإجابة على الشطرنج  أسئلة.  وهكذا تدرك أن\nاللغة تجسد حقًا الكثير من التجربة الإنسانية والكثير مما\nيعنيه أن تكون ذكيًا.  وأعتقد \n أن أحد مؤسسي شركائي يقول إن تورينج كان يتجول لسبب ما.  كما تعلمون، إنه حقًا رائع حقًا. إحدى أفكاره الرائعة هي، انظر، سيتعين عليك أن تتعلم الإجابة. سيتعين عليك بناء آلة يمكنها فهم\nكيفية إنجاز المهام. لا نستطيع.  وكانت تلك بالنسبة لي هي\nاللحظة التي حدث فيها كل شيء. لكن بالطبع، كان هذا مثل\nعام 2008، لذلك لم ينجح أي شيء في الذكاء الاصطناعي، ولمدة سبع سنوات أخرى نظرنا من\nالخارج إلى التعلم العميق وحقيقة أن أجهزة الكمبيوتر\nأصبحت سريعة بما فيه الكفاية، وأنها أصبحت الآن مفيدة تجاريًا. أننا بدأنا ندرك أنه، ربما هناك بالفعل\nفرصة لتحقيق هذا الحلم. وكما تعلمون، لقد اجتمعنا أنا وآخرون معًا لأننا أردنا أن نرى ما إذا كان\nبإمكاننا توجيه تكنولوجيا الذكاء الاصطناعي بطريقة إيجابية. أردت أن أرى ما إذا كان بإمكاننا\nبالفعل بناء نوع الآلة التي تحدث عنها تورينج، ذكاء بمستوى الإنسان،\nما نسميه الذكاء الاصطناعي العام، وأن يكون ذلك شيئًا\nيفيد البشرية جمعاء. هذه هي مهمة OpenAI. لذلك نحن ندفع التكنولوجيا إلى الأمام. نريد أن يكون\nمفيدًا بالفعل، وأن يكون آمنًا، وأن نوزع تلك الفوائد على الجميع.  أعتقد أننا نعمل على ذلك\nمنذ ثماني سنوات. وفي ذلك الوقت، كما تعلمون، نواصل القيام بنفس النشاط، حيث نبني شبكة عصبية أكبر، ونجعلها أكثر قدرة، ونجعلها أكثر توافقًا، ونجعلها أكثر أمانًا. وعلى مدار العامين الماضيين، بدأنا أيضًا في\nنشره وجعله مفيدًا. وهذا ما أعتقد أنه مثير للاهتمام بالنسبة لي بشأن هذه التكنولوجيا. إنه ليس مثل الاندماج حيث يبدو الأمر كما لو أنك حصلت عليه أو لا. إنها كل خطوة على طول الطريق التي\nيمكنك من خلالها إحداث تأثير فعلي، ويمكنك بالفعل\nالبدء في إفادة الناس. ولذا أعتقد أن هذا أمر جيد، وكما تعلمون، ستتمكن من رؤية فوائد\nما قمت ببنائه وتعلم كيفية\nالتخفيف من جميع الجوانب السلبية. ولذا أعتقد أن هذه هي\nالمرحلة التي نحن فيها. - نعم، هناك مجموعة من الأمور في ذلك. أعني، كما تعلمون، يبدو أنه بناءً على الوقت الذي\nتعمل فيه على أشياء تتعلق بالذكاء الاصطناعي، فأنا أكبر بقليل من 10 سنوات أو أكثر بقليل من\nذلك، أكبر منك. لكن كما تعلمون، في منتصف أواخر التسعينيات عندما كنت في الكلية، وكنت أعمل مع بعض\nالرواد الأوائل وكان بعضهم أساتذتي وكان الأمر نفسه.  لقد كنت متحمسًا جدًا\nللذكاء الاصطناعي.  لقد قرأت الخيال العلمي، وقلت، أوه، هذا\nسيستغرق إلى الأبد، إذا حدث. وحتى في وجهة نظرك، فقد واجهت نفس الشيء\nبعد حوالي 10 أو 12 عامًا. وبعد ذلك، حتى عندما كنتم\nتفكرون جميعًا في بدء OpenAI، هذا، كما تعلمون،\nما ذكرتموه AGI، الذكاء العام الاصطناعي، أعتقد أن العديد من الأشخاص المفكرين،\nإذا كنت صادقًا، حتى نفسي، وأنا أميل إلى\nالتفاؤل جدًا بشأنه  الأشياء، كنت أعتقد أن هذا أمر\nوهمي بعض الشيء، أن نبدأ الآن\nالعمل على، مثل، كما تعلمون، ولا نعتبره حتى مختبرًا للأبحاث. أعني، أعتقد أن الأمر\nأشبه بمختبر أبحاث، لكن في الواقع أن تبدأ\nمنظمة لديها.  هل تعتقد أن\nالناس يقولون لك ذلك؟ كيف قررت أن تفعل ذلك على أي حال؟ - أوه نعم. أعني أننا تلقينا الكثير من\nالتعليقات السلبية للغاية من المجتمع. والشيء الذي\nوجدته أكثر إثارة للاهتمام هو أننا كنا نتحدث عن\nسلامة الذكاء الاصطناعي قبل أن يصبح الأمر رائعًا. وفي الواقع أتذكر أنني\nتحدثت مع أحد المرشحين الذين عملوا في مختبر كبير للذكاء الاصطناعي حيث قال: \"نعم، أعتقد أن سلامة الذكاء الاصطناعي العام هي المشكلة الأكثر أهمية. أعتقد أن الأمر مهم حقًا. ولكن إذا اقتبست كلامي في\nهذا الشأن،  سأنكر كل شيء.\" وأعتقد أن هذا ما يميزنا هو أننا كنا على\nاستعداد حقًا للتفكير في أين ستتجه الأمور والتصرف بناءً عليها. نحن لسنا فقط. مثل أن يكون هناك أشخاص آخرون في هذا المجال، ورواد آخرون كانوا\nيدفعون هذا النوع من التكنولوجيا إلى الأمام، وكانوا، كما تعلمون، نوعًا ما أيضًا أعتقد أنهم أصحاب\nرؤية من حيث التفكير، كما تعلمون،\nحتى قبلنا بسنوات عديدة للبدء في هذه المشكلة. لكنني أعتقد أنه ربما، كما تعلمون، لا أعرف ما إذا كان هذا\nمجرد شيء في حمضنا النووي أو إذا كان شيئًا يتعلق بنوع ما، كما\nتعلمون، بالنسبة لي شخصيًا، شعرت\nوكأنني أمضيت خمس سنوات في بناء تقنية  شركة.  لقد كنت مستعدًا حقًا للاشتراك\nفي مشكلة كنت مستعدًا للعمل عليها لبقية حياتي. وكان من الواضح جدًا بالنسبة لي أنه لو تمكنت من\nالتعمق قليلاً، حتى لو كنا نتحدث بعد 300 عام تقريبًا وجاء الذكاء الاصطناعي العام، فسيكون الأمر يستحق ذلك. يمين؟ وكما تعلمون، هناك احتمال أن يكون ذلك في وقت أقرب. ولذلك أعتقد أن هذا\nالإطار هو الإطار الزمني، يمكنك\nمراوغته، يمكنك مناقشته، يمكنك التحدث عن هذه الأشياء، ولكن بشكل أساسي\nالاشتراك في تأثير أهم تكنولوجيا سيخلقها البشر على الإطلاق. مثل هذا شيء يمكنني أن أتخلف عنه. - والأمر الملحوظ، وأعتقد أن هذا ليس\nخبرًا جديدًا للكثير من الناس لأن OpenAI كان في\nالأخبار كثيرًا مؤخرًا، كما تعلمون، لديك\nنماذج GPT هذه، كما تعلمون، المحولات التوليدية المدربة مسبقًا  ،\nهذه التكنولوجيا هي، كما تعلمون، نكهة الشبكات العصبية، التي كانت موجودة في مجتمع الذكاء الاصطناعي\nلبعض الوقت، وكان لديكم جميعًا GPT-1، GPT-2، قال الناس، أوه، هذا مثير للاهتمام، يمكنه الكتابة  ، ولكن، كما تعلمون، ليس لديه حقًا التعامل الجيد مع المعرفة،\nGPT-3 أفضل. وبعد ذلك ظهر ChatGPT\n، وهو عبارة عن واجهة، بدأ يذهل الناس\nقليلاً.  ومن الواضح أننا\nأعلنا معكم جميعًا أننا نعمل\nمعًا على GPT-4 لاستخدامه في أكاديمية خان، لكن من الواضح أنكم جميعًا كنتم تقومون بكل العمل لتطويره.  لم تعد فكرة\nالذكاء الاصطناعي العام (AGI) أو الذكاء العام الاصطناعي تبدو غريبة بعد الآن.  كما تعلمون، حتى بعض\nما أعتقد أن العديد من الأشخاص قد جعلوا GPT-4 يفعله يبدأ في الشعور بهذا النوع من الشيء. أعتقد أن سؤالي الأول هو، ما الذي تعتقدون أنكم\nستفعلونه جميعًا حتى تصلوا إلى هذا المكان، كما\nتعلمون، حيث يوجد الكثير والعديد من الأشخاص الذين يعملون في هذا المجال، والعديد من المنظمات الأكبر حجمًا التي\nلديها المزيد من الموارد. هل تعتقد أنه شيء\nتفعله بشكل مختلف أو كيف تتعامل معه أم لا؟ نعم، ما رأيك هو خاص؟ - نعم، أعتقد أنه سؤال صحيح. أعني، أعتقد أننا جزء من اتجاه أكبر بكثير، أليس كذلك؟ إنه مثل تاريخ أكبر بكثير، أليس كذلك؟ تنظر إلى جميع منحنيات الحوسبة، لمدة 70 عامًا كان لدينا\nهذا النمو المتسارع وكما تعلم، في عام 2000\nكان راي كورزويل يقول، مهلاً، فقط انظر إلى الحوسبة، وهذا سيخبرك نوعًا ما\nبما سيكون ممكنًا. وهذا هو الوقود للتقدم. وظن الجميع أنه مجنون. والآن أعتقد أنهم\nيعتقدون أساسًا أنه على حق. وأعتقد، كما تعلمون،\nأنكم تفكرون في مقدار الهندسة التي\nتدخل في قدرتنا على تقديم شيء مثل GPT-4، بدءًا من\nالبنية التحتية الحاسوبية الفعلية وحتى جميع مجموعات البيانات والأدوات التي نستخدمها، وهذا حقًا  هذا المسعى الهائل للإنسانية بعدة طرق. لكن على وجه التحديد، كما\nتعلمون، تمكنا من التنفيذ لأننا\nجمعنا معًا أشخاصًا من خلفية بحثية\nوخلفية هندسية. وأعتقد أن هذا شيء فريد جدًا، أليس كذلك؟  وأعتقد أن\nالسلامة هي جزء أساسي من هذا النوع الذي يأتي من\nجميع الزوايا المختلفة. إنه نوعاً ما، كما تعلمون، سواء من الناحية العملية أو من الناحية النظرية،\nالتفكير فيما، كما تعلمون، كيف ستتصرف هذه الأنظمة، وكيف \nستسير على ما يرام وكيف ستسير على نحو خاطئ. لكن نعم، أعتقد أن\nالشيء الذي كان مثيرًا للاهتمام بالنسبة لي عندما بدأنا، هو النظر إلى جميع\nالمعامل الأخرى، ويمكنك حقًا أن ترى أنها تأتي عادةً من\nخلفية بحثية أولى.  وهكذا يكون لديك هؤلاء المهندسين البحثيين الذين يُقال لهم ما يجب عليهم فعله، وعلى علماء الأبحاث أن\nيفعلوا ما يريدون. وأنت تعتقد أن هذا لا\nيبدو وكأنه الطريقة التي ستبني بها نظام عمل بالفعل. يبدو أنها طريقة رائعة\nللحصول على مجموعة من الاستشهادات، ولكن إذا كنت تريد بالفعل أن يكون لك تأثير وتطور شيئًا ما، فأنت تحتاج فقط إلى هيكلة المنظمة بشكل مختلف. وهذا صعب، كما\nيبدو سهلًا على الورق، ولكن هناك طرق متضاربة جدًا للتفكير في الأشياء إذا\nكنت قادمًا من خلفية عملية للغاية مقابل إذا كنت قادمًا من خلفية أكاديمية أكثر. وعلينا بطريقة ما أن نعتمد على هؤلاء. وأعتقد أننا قمنا\nبحل إصدارات أكثر تعقيدًا من هذا النوع\nمن العقليات المختلفة، والخلفيات المختلفة،\nوالمشاكل، مثل مرات عديدة. وأنت لا تحلها بالكامل أبدًا. تنتقل إلى\nنسخة أكثر تطوراً منه. لذلك أعتقد أن هذا هو\nالميل إلى الانزعاج، والاتكاء على الأجزاء الصلبة. - لا، هناك الكثير من\nالأسئلة التي لدي لأنني\nأعتقد أن هناك شيئًا فريدًا يجب أن تفعلوه جميعًا. أنتم لستم جميعًا منظمة كبيرة، وأعتقد أنكم بالتأكيد أكبر من وزنكم. لكن أحد الأشياء التي\nتحدثت عنها كثيرًا، وكان هذا أيضًا أحد\nالأسباب لبدء OpenAI كمنظمة غير ربحية،\nوسنتحدث قليلاً عن كيفية تطور الأمور منذ ذلك الحين، ولكن  تستمر في ذكر السلامة، كما تعلمون، الذكاء الاصطناعي أمر مثير وربما مخيف لبعض الناس.  لقد قرأنا جميعًا الخيال العلمي المثير والبائس. عندما تتحدث عن السلامة، ما الذي تتحدث عنه؟ ما هي المخاوف الحقيقية التي\nيجب على الناس القلق بشأنها ووضع القيود حولها، وما هي المخاوف التي\nقد لا تكون مبررة؟ - نعم، أعتقد أنه كان هناك\nتاريخ طويل من التفكير في سلامة الذكاء الاصطناعي، أليس كذلك؟  وأعتقد أن هناك بعضها\nيسبق، كما تعلمون، ويعود إلى الخمسينيات والستينيات. يمكنك أن تجد أشخاصًا مثل آرثر\nسي كلارك يتحدثون عن امتلاك آلة ذكية. وكما تعلمون، ما يميز البشر عن غيرهم هو حقيقة أننا أذكياء.  وهذا شيء جديد، أليس كذلك؟ هذه الفكرة كلها. ولذا أعتقد أننا يجب أن نتعامل مع الأمر بقدر متساوٍ من الإثارة\nلما يمكن إنجازه والحذر بشأن الأخطاء التي يمكن أن نرتكبها. لذا أعتقد أن هذا أمر\nصحيح تمامًا، أن تكون لديك هذه المشاعر المختلطة وأن تندهش في نفس الوقت\nمن أي شيء جديد، ولكن أيضًا اسأل أين يتجه هذا وأين هذا بالذات؟ أين يمكن أن تكون المزالق؟ أعتقد أن هذه هي الطريقة الوحيدة التي\nيمكننا من خلالها التنقل عبر الفضاء بشكل صحيح. لكنني أعتقد أن الشيء الآخر الذي كان مثيرًا للاهتمام للغاية\nهو مدى مفاجأة الذكاء الاصطناعي وكيف يتم تنفيذه. كما كنت تفكر في\nالتسعينيات، اعتقد الجميع أنه إذا قمت بحل لعبة الشطرنج\nفسوف يوصلك ذلك إلى الذكاء الاصطناعي العام. وفي الواقع، كانت لعبة الشطرنج أول شيء قمنا\nبحله بعدة طرق، ولم يذهب الأمر إلى أبعد من ذلك. وأعتقد أنني رأيت نفس الشيء\nفيما يتعلق بالتفكير في السلامة، أليس كذلك؟ إذا فكرت في الأمر على أنه\n شيء واحد كان من الممكن بناؤه، اتجاه واحد أعتقد أنه كان ممكنًا، هو أنك ستبني هذه العناصر التي يجب أن تبقى على قيد الحياة وتتكرر وتتطور في بعض الأحيان  نوع من المحاكاة المعقدة متعددة الوكلاء. يبدو ذلك مرعبًا حقًا، أليس كذلك؟ حتى نعرف ما\nيستطيع هؤلاء العملاء فعله. وكما تعلمون، لكي تكون قادرًا على الثقة بهم، عليك حل بعض\nالمشكلات الصعبة حقًا. ولذلك يتم بذل الكثير من الجهد\nفي التفكير في كيفية تصميم وظيفة المكافأة التي تكتبها على وجه\nالتحديد والتي لا تحتوي على أي شيء، كن حذرًا فيما ترغب فيه. ولذلك كان هناك الكثير من التفكير في هذه الأنواع\nمن الطرق لحل المشكلات، ولكن نموذج GPT\n، لم يتوقعه أحد، إنه مختلف تمامًا عما تتوقعه من\nمنظور السلامة. وبالنسبة لي، الدرس المستفاد هو هذا، حتى معرفة كيفية\nالتعامل مع التكنولوجيا ومعرفة ما\nيمكن استخدامها فيه وكيفية\nتوجيهها في الطريق الصحيح. لا يعني ذلك بالضرورة أن هناك\nحدودًا للبصيرة، ولكن أعتقد أن لدينا تاريخًا من الثقة المفرطة في الأشياء الخاطئة.  وهكذا، كما تعلمون، أحد الأمثلة التي يمكنك من خلالها رؤية الرأس هو\nإذا نظرت، على سبيل المثال، إلى التعلم المعزز\nمن التفضيلات البشرية. وهذا ما نستخدمه لضبط\nسلوكيات هذه النماذج. وهذا شيء\nمختلف تمامًا عن GPT-3، حيث نقوم بإصدار النموذج بعد تدريبه على\nمجموعة البيانات الأساسية على GPT-4، حيث نكون\nقادرين بالفعل على ضبطه واختيار القيم\nالتي  المعروضات النموذجية.  وقد بدأنا بالفعل في تطوير تلك التكنولوجيا في عام 2017 قبل\nوجود أي من هذه النماذج. ولذا أعتقد أنه\nيمكنك رؤية المستقبل قليلاً. يجب أن تفكر في كيفية\nاستخدامهما، مع التأكد من توافقهما مع ما يريده المشغل، كما تعلم، ومع ذلك المستخدم. أنهم ليسوا نوعًا ما غير قابلين للإيذاء إذا أراد شخص ما أن يفعل شيئًا ما، ولكن المجتمع لديه\nمجتمع غير قانوني أو ضار لشخص آخر،\nيجب أن تكون هناك بعض الحدود. وأعتقد أيضًا أن\nهناك تأثيرات على النظام البيئي حيث يمكنك بطريقة ما أن\nتتخيل أن الذكاء الاصطناعي، جميعهم يقومون بما\nيُطلب منهم القيام به محليًا، لكنه يضيف بطريقة ما إلى عالم أسوأ. ولذلك أعتقد أنه سيتعين علينا\n مواجهة سلسلة متزايدة من المخاطر مع مرور الوقت.  كما تعلمون، لقد\nتخرجنا نوعًا ما في بعض النواحي من نوع المخاطر التي تنطوي عليها هذه النماذج. بالنسبة لـ GPT-3، أعتقد أننا كنا قلقين حقًا بشأن المعلومات الخاطئة، ولكن عندما وصلنا إليها حقًا، رأينا أن الناس\nيريدون فقط توليدها، وأن ناقل إساءة الاستخدام الأكثر شيوعًا\nهو إنشاء إعلانات طبية لمختلف الأدوية. وأعتقد أنه مع GPT-4،\nلديك نوع جديد من فئة المخاطر وأعتقد أنه في المستقبل سيكون لديك\nفئات جديدة من الفوائد والمخاطر التي تسير جنبًا إلى جنب. - إذن، كما تعلمون، من الواضح أن\nأحد الأشياء المثيرة للاهتمام بشأن\nحديثنا نحن الاثنين في مؤسساتنا، هو أنكم جميعًا تواصلتم معنا، كما تعلمون، منذ ستة أشهر عندما بدأتم\nللتو في الحصول على  الإصدار الأول من GPT-4.  وأعتقد أن أحد الأسئلة التي\nلدي هو، كما تعلم، لماذا تواصلت معنا في ذلك الوقت؟ - نعم، حسنًا، بالنسبة لي شخصيًا،\nشعرت دائمًا بأنني أحد الدوافع لبناء\nأنظمة الذكاء الاصطناعي، ولمحاولة بناء الذكاء الاصطناعي العام، ولإعطاء الجميع معلمًا شخصيًا، كما أنا شخصيًا، أعتقد أن\nالعديد من الأشخاص لديهم قصة عن ذلك  أحد المعلمين الذي\nفهمهم حقًا، وساعدهم على تحقيق\nموضوع ما والتحمس له. ولكم أن تتخيلوا فقط ما يمكن أن\nيحدث إذا تمكن الجميع من الوصول إلى مثل هذا المعلم على مدار الساعة طوال أيام الأسبوع، والذي يمكنه حقًا\nفهمهم وتحفيزهم. وأشعر أن هذا يتماشى تمامًا مع ما تبنيه أكاديمية خان. وأنا، كما تعلمون، الإمكانات التي تريدون إطلاقها لدى كل طالب. وهكذا كان الأمر كما لو أننا\nأدركنا أنه ربما يمكننا بالفعل إحداث تغيير في التعليم، وربما يمكن تطبيق ذلك هناك. كان من الواضح جدًا أن أكاديمية خان كانت أول نقطة اتصال. - ومنذ ذلك الحين، أعتقد أننا عملنا معًا، ومن الواضح الآن أن GPT-4 موجود، ما الذي تأمل أن يصبح عليه هذا؟ مثل كيف، كيف تأمل أن\nيستفيد عالم التعليم من هذا؟ من المعروف أنه عندما ظهر ChatGPT، تسبب في الكثير من التوتر\nفي عالم التعليم. كان الناس يقولون، أوه،\nسيستخدم الأطفال هذا للغش في مقالاتهم\nأو أداء واجباتهم المدرسية. كيف ينبغي للمعلمين أن يفكروا\nفي هذا الأمر الآن؟ - نعم، أعتقد أنني\nسأقول أن هناك نوعًا ما، كما تعلمون، نسخة خاصة بالتعليم مما كنت أقوله بشكل عام، أليس كذلك؟ أن هناك فرصا، وهناك مخاطر. وأعتقد أن معرفة كيفية التنقل في هذا أمر مهم حقًا. وعليك أن تميل\nإلى هذا التوتر، أليس كذلك؟ لذلك، أعتقد أنه من\nالمهم أن يتعلم الناس التفكير بأنفسهم، ولكن أعتقد أنه من المهم أيضًا أن يتمكن الطلاب، كما\nتعلمون، من الحصول على أفضل ما في التكنولوجيا وأننا\nنجعل هذه التكنولوجيا في متناول الجميع  متاح\nللأشخاص الذين قد لا يتمكنون من الحصول على أدوات تعليمية رائعة بخلاف ذلك. ولذا أعتقد أن هناك، كما تعلمون، أملي هو أن نكون بمثابة\nمنصة يستطيع المعلمون والمعلمون\nتشكيلها حسب رغبتهم والمساعدة في\nالعمل مع طلابهم وسد الفجوات التي لا يمكنهم القيام بها. ولذا، كما تعلم، أعتقد أن\nأنواع التطبيقات، سأكون في الواقع أشعر بالفضول نوعًا ما، يا سال، بشأن ما كنت تراه باعتباره أكثر الأشياء التي تثير حماسك. - نعم. حسنًا، كما تعلمون، من الواضح أننا وضعنا الكثير في هذا الأمر ونحن متحمسون جدًا، كما تعلمون، لقد قمنا حتى بتجربة، كما تعلمون،\nما نسميه خانميغو، والذي هو في الأساس تجسيد للذكاء الاصطناعي  في أكاديمية خان مع\nبعض المناطق التعليمية الكبيرة، والتي اشتهر بعضها بحظر ChatGPT.  وكما تعلمون، فهم يقدمون لنا ردود الفعل، وهذا ما أردناه. أردنا تسخير\nقوى هذه التكنولوجيا، ولكن وضعنا بعض الحواجز حولها، بحيث يتم استخدامها بشكل منتج للطلاب بحيث، كما تعلمون، يستطيع المعلمون\nرؤية ما يفعلونه، وهو أمر سليم من الناحية التربوية الآن.  ومن المثير للاهتمام الآن أنه قد خلق نقاشًا كبيرًا حقًا حيث يكون الناس على حالهم، حسنًا،\nهذا أمر رائع إذا كانوا داخل الصندوق الرملي، ولكن ما الذي يمنعهم من الذهاب إلى مكان آخر؟ وسيقوم شخص آخر\nبإنشاء تطبيق يستخدم واجهة برمجة التطبيقات للقيام بشيء ما، كما تعلمون، هنا أو هناك. لذا، أعتقد أن هناك\nبعض الأسئلة الحقيقية هناك. أعتقد أنني ربما سأحول\nذلك إلى سؤال، كيف تفكرون جميعًا\nفي هذا من حيث، هل سيكون الأمر\nمشابهًا إلى حد ما لمتاجر التطبيقات الكلاسيكية الخاصة بك حيث يوجد\nالقليل من المراجعة التحريرية لكيفية تعامل الناس  باستخدام واجهة برمجة التطبيقات (API) أم أنها ستكون أقرب إلى\nإخبارك، فلنرى ما سيحدث. كيف تفكرون جميعا في هذا؟ وأعتقد أننا يمكن أن نتحدث\nعن التعليم بشكل عام أو التعليم على وجه التحديد أو بشكل عام. - نعم. حسنًا، أعتقد أن الحقيقة\nهي أن هذه التكنولوجيا جديدة جدًا وهناك\nالكثير لنتعلمه، أليس كذلك؟ لكننا مدروسون للغاية بشأن هذا الأمر. إننا نقضي الكثير من الوقت في\nالتفكير في كيفية بناء الأشخاص على\nمنصاتنا، وما هي قواعد المشاركة،\nمحاولين الحصول على الكثير من المدخلات. لذلك نحن نتفاعل كثيرًا مع المعلمين ومع الأشخاص الآخرين\nوفي مختلف المجالات لأنني أعتقد في نهاية المطاف أن القرار بشأن كيفية دمج هذا النوع\nمن التكنولوجيا في العالم، لا ينبغي أن يكون متروكًا لنا وحدنا. وكأننا بحاجة إلى أن نكون جزءًا من ذلك بالتأكيد، إذا كانت هذه هي التكنولوجيا الخاصة بنا، لكننا نعتقد أنه من المهم حقًا الحصول على مدخلات واسعة من الجميع. لذلك أعتقد أن هذا في الواقع\nهو العامل الأكثر أهمية. ولذلك يجب أن تتوقع التطور، أليس كذلك؟ يجب أن تتوقع منا أن نحصل على البيانات وندرك أنه مثل هذا\nالشيء المحدد الذي لعب بشكل رائع، فإن هذا الشيء المحدد لم يحدث، ثم تعلم كيفية التكيف. لذلك آمل، كما تعلمون، رقم واحد، أن أعتقد أنه من المهم حقًا إظهار الاتجاه الصعودي، أليس كذلك؟ أعتقد أنه من السهل أن نرى فقط الأشياء التي يمكن أن تسوء. وأعتقد أنه من المهم\nألا تدفن رأسك في الرمال، لكن السبب وراء بناء\nهذا في المقام الأول، صحيح، هو\nتحقيق تلك الفوائد فعليًا. ولذا فإن ما يسعدني حقًا\nرؤيته هو أن أكاديمية خان أو أي شخص آخر سيقوم\nبالبناء في هذه المساحة يتفاعلون حقًا مع ما يحبون،\nويتعمقون مع المناطق، ويتحدثون إلى المعلمين ويكتشفون حقًا الشكل الدقيق الذي يريدونه  . بمجرد أن يكون لديك\nمثال إيجابي لشيء ناجح، فمن السهل بناء\nمعايير حوله، أليس كذلك؟ إذا لم يكن لديك ذلك على الإطلاق، فأنت فقط تطلق النار في الظلام. وقد رأينا هذا بالفعل، كما تعلمون، آخر مرة قمنا فيها بإعادة نشر منشور مدونة\nحول معايير السلامة لنشر نماذج اللغة. وكل ذلك جاء بعد\nعامين من عمليات النشر وارتكاب الكثير من الأخطاء بصراحة. ولذا أعتقد أن هذا\nالنشر المتكرر للتعلم من الممارسة،\nهو، في اعتقادي، الشيء الأكثر أهمية الذي يمكننا جميعًا القيام به الآن. - لا، أنا أتفق تماما. من الواضح أننا نستثمر كثيرًا لأننا بشكل\nعام متفائلون جدًا بشأن الاتجاه الذي سيتجه إليه كل هذا. وكما تعلمون، لم أستطع التحدث بصراحة عن\nذلك عندما كانت هناك كل هذه المناقشات في ChatGPT في وسائل الإعلام، ولكن بمجرد أن تمكنا\nمن ذلك، كنت أقول، انظر، هذا، أعلم أن هناك بعض المخاوف، ولكن إذا كنت  ضعها في الإطار الصحيح مع حواجز الحماية المناسبة، ليس فقط يمكنك التخفيف من تلك المخاطر، ولكن يمكنك تحقيق تقدم هائل، ومعلم لكل طالب\nوتقديم طرائق جديدة تمامًا كانت ستبدو وكأنها\nخيال علمي بدون الذكاء الاصطناعي، وأشياء مثل  قم بإجراء مقابلة مع شخصية تاريخية، ومارس مهاراتك في المناظرة.  كما تعلمون، يمكننا أن نجعل\nالمعلمين قادرين على المساعدة في إنشاء\nخطط الدروس، إلى آخره، إلى آخره.  كما تعلمون، لقد أجريت أحد المناقشات\nمع الكثير من الأصدقاء مؤخرًا،\nالأصدقاء ذوي المعرفة الذين يعرفون الذكاء الاصطناعي، وما إلى ذلك، وقد دخلنا في\nهذا النقاش الكلاسيكي حول ما إذا كانت الأداة\nستقلل من القدرة البشرية أو تتوسع  القدرة البشرية ؟ أنا على جانب التوسع. إذن، كما تعلمون، هذا هو المكان الذي توجد فيه بطاقاتي، وهذا سيجعلنا أكثر إبداعًا. بطريقة غريبة، قد\nيجعلنا نكتب أكثر لأننا سنصبح محررين أكثر وسنقوم بصياغة المزيد. لكنني، كيف تفكر في ذلك عندما يقول الناس، أوه واو، كما تعلم، الآن سيقلل الناس من\nالأشياء التي يفعلها البشر، ولن يطوروا\nمهاراتهم في الكتابة، ولن يطوروا الإبداع. لأنهم سيعتمدون أكثر على\nالذكاء الاصطناعي من أجل ذلك. - نعم، أعني أنني معك بالتأكيد يا سال. مثلًا، أعتقد أن\nالتأثير الصافي سيكون إيجابيًا للغاية\nوأعتقد أننا جميعًا سنحصل على هذه القوى الخارقة للذكاء الاصطناعي، وسنتمكن من تحقيق أشياء\nلا يمكننا تحقيقها بطريقة أخرى. سوف يحب الكدح أن يستنزف بعيدًا. كل تلك الأشياء التي\nأعتقد أنها موجودة هنا، أليس كذلك؟ إن لم يكن في الأفق. ولكن بالطبع سيكون الأمر بمثابة\nدفن رأسك في الرمال إذا قلت أن هذا هو التأثير الوحيد، أليس كذلك؟ أعتقد أن هذا هو التأثير الصافي وأعتقد أنه سيكون قوياً للغاية. لكنني أعتقد أنه ستكون هناك\nحكايات عن أماكن، كما تعلمون، نعم، مثل الأشخاص الذين أحبوا حرفة معينة والآن أصبحت هذه الحرفة سلعة، أليس كذلك؟ أنه كان هناك عائق أمام الدخول. كان عليك بناء مهارة\nوالآن يمكن لأي شخص القيام بذلك. ومن ناحية هذا\nشيء جميل، أليس كذلك؟ لأن هناك كل هؤلاء\nالأشخاص الذين يمكن الآن إطلاق العنان لإبداعهم، أليس كذلك؟ هناك، كما تعلمون، الجميع، كما تعلمون، مثلما تفكر في عدد الأشخاص الذين لديهم هاتف ذكي؟ ولذا، إذا كنت قادرًا على\nالوصول إلى كل من لديه هاتف ذكي لذكاء اصطناعي قوي جدًا ويمكنه البدء في الإنشاء بطريقة قبل أن ترغب في شراء مجموعة من البرامج الاحترافية،\nفسيتعين عليك الذهاب إلى  المدرسة والحصول على الكثير من التدريب. كما ترون كيف أن\nهذا العالم مختلف. لكن الأمر أكثر إيجابية في كثير من النواحي\n، كما تعلمون. لكنني أعتقد أن هذا التغيير والاستعداد لذلك أمر مخيف. وأعتقد أن هذا\nشيء يجب أن ننظر إليه بعيون مفتوحة على مصراعيها. - نعم على الاطلاق. وكما تعلمون، في\nالوقت المتبقي لنا، في كل مرة أتحدث إليكم،\nتقولون أحيانًا، أوه، وبالمناسبة،\nنحن نعمل أيضًا على هذا. وبعد ذلك أخبرني، أرني وأقول، أوه، هذا أمر مهم. مثل، كما تعلمون، إنه مثل، وهناك المزيد. حولنا إلى هذه المحادثة، فقط، كما تعلمون، نرسم\nصورة للناس حول ما سيأتي\nبقدر ما يمكنك التحدث عنه وما تعتقد أنه التداعيات وكيف تحاولون جميعًا التركيز على أحد هذه الاتجاهات أو  آخر. - نعم، حسنًا، أعتقد\nعلى أعلى مستوى، أننا جادون حقًا\nبشأن هذا المسار نحو الذكاء الاصطناعي العام. مثلما نعتقد أن هذا هو المسار الذي يسير عليه المجتمع، فإن العالم يسير عليه. أعتقد أن هذا هو المسار الذي\nسلكناه لفترة طويلة. إذا نظرتم إلى كل هذه المنحنيات وتعلمون، أعتقد أننا قد\nحملنا الشعلة بعدة طرق ونشعر أن\nمسؤوليتنا الرئيسية ليست مجرد بنائها،\nبل بنائها، أليس كذلك؟ وعلى المدى القصير نوعًا ما، أعتقد أنك ترى\nأشياء مثل، كما تعلمون، GPD 4 لديه مدخلات رؤية. وهذا شيء ما\nزلنا نجربه مع شريك واحد. لكنني أعتقد أن ذلك سيكون\nأيضًا بمثابة خطوة جديدة من حيث سهولة الاستخدام، أليس كذلك؟ أنك ستتمكن من تقديم المستندات، وستكون قادرًا على، كما تعلم، إذا كان لديك رسم تخطيطي\nيمثل جزءًا من المنهج التعليمي في أكاديمية خان، وأنك ستفهم\nهذا الرسم البياني مع أسئلة الطلاب\nحول هذا الموضوع المهم. سوف تكون قادرا على القيام بذلك. ولذا أعتقد أننا\nسنفتح إمكانية الوصول بعدة\nطرق، كما تعلمون، مما يجعل هذه الأشياء تعمل بشكل أسرع\nوأرخص وأكثر سهولة في الوصول إليها. هذا دائمًا هو التركيز الكبير بالنسبة لنا. ومحاولة حقا للتحسين. أعتقد أن الشيء الذي\nنفتقده الآن بطرق عديدة هو القدرة على\nتوليد أفكار جديدة، أليس كذلك؟ أن نكون قادرين على حل المشكلات الأصعب وكل ما نفكر فيه، نحن نستكشفه، وكما تعلمون، مرة أخرى، نفعل ذلك مع\nالتركيز على السلامة أولاً. - نعم، حسنًا، يجب أن أقول لجريج، شكرًا جزيلاً لك على قضاء الوقت وإحضارنا في هذه الرحلة لأنه يبدو حقًا أننا\nنعيش في كتاب خيال علمي وهو نوع من هذه الكتب اختر\nمغامرتك الخاصة  كتب الخيال العلمي حيث يمكن أن تذهب في اتجاهات مختلفة، ولكن أعتقد أنه طالما أن هناك عددًا\nكافيًا من الأشخاص يفكرون في كيفية تعظيم\nالفرص والفوائد وتخفيف أكبر عدد ممكن من المخاطر، فأنا كذلك، ويبدو أنك أيضًا نحن كذلك  متحمس جدًا لما قد يكون عليه العالم\nبسبب هذا. - وأنا أيضًا، نعم، كانت محادثة رائعة. - عظيم، شكرا لانضمامك. - نعم، شكرا لك.",
    "t_italian": "- Ciao a tutti, sono Sal\n, della Khan Academy, e come alcuni di voi sanno, ho\npubblicato il mio secondo libro, \"Brave New Words About the Future of AI in Education and Work\". È disponibile ovunque\ntu possa acquistare i tuoi libri, ma come parte della ricerca per quel libro, ho fatto alcune interviste con\nalcune persone affascinanti, che stai per guardare. Quindi oggi abbiamo Greg Brockman. Sono davvero entusiasta di averti qui, Greg. Per quelli di voi che non lo sanno, Greg è il co-fondatore, presidente e presidente di un'organizzazione di cui alcune persone parlano in\nquesti giorni chiamata Open AI. E anche noi della Khan Academy\nabbiamo fatto qualcosa con OpenAI. E questo è molto emozionante perché questo è l'\ninizio di un nuovo podcast, un nuovo live streaming, una nuova cosa che stiamo facendo\nchiamata Brave New Words, che è anche un libro su cui\nstiamo lavorando. Quindi Greg, grazie mille per esserti unito a noi. - Grazie per avermi ospitato. - Quindi iniziamo, assicurandoci che tutti coloro che guardano e ascoltano abbiano una comprensione condivisa. Raccontaci qualcosa di Open AI e di come hai deciso di avviarla e magari di\ndove è andata da allora. - Sì, quindi, sai, per quanto mi riguarda, mi sono entusiasmato per la prima volta all'idea dell'intelligenza artificiale quando ho letto l'articolo di Alan Turing del 1950 sul test di Turing,\nche, hai letto Sal? - Sai, non ho letto il giornale. Lo conosco molto bene, ma in realtà non leggo il giornale. - Va bene. Quindi consiglio di leggerlo\nperché, sai, la prima metà è tutta\nincentrata sul test di Turing, ma la seconda metà riguarda come risolverlo? E lui ha detto, guarda, non programmerai mai\nuna risposta a questa cosa. È semplicemente troppo difficile. Ma potresti costruire una\nmacchina in grado di imparare. - E giusto per fermarti,\nper chi non lo sa, cos'era il test di Turing? Solo per essere sicuri che\ntutti siano sulla stessa lunghezza d'onda. - Sì, il test di Turing è l'\nidea secondo cui potresti distinguere tra una macchina e una persona\navendo un giudice che parla con una persona, parla con una macchina, e che se sono\nindistinguibili, potresti dire che quella macchina è davvero  intelligente. E quindi, ancora una volta, devi\nessere in grado non solo di, sai, chiacchierare,\ndevi essere in grado, nel suo articolo dice, okay, come il giudice fa domande sugli scacchi e tu devi rispondere a scacchi  domande. E così ti rendi conto che il\nlinguaggio cattura davvero gran parte dell'esperienza umana e molto di ciò che\nsignifica essere intelligenti. E penso che sia una\nspecie di, sai, che uno dei miei co-fondatori dice che Turing era in tournée per un motivo. Sai, è davvero, davvero brillante. Una delle sue grandi intuizioni è: guarda, dovrai imparare una risposta. Dovrai costruire una macchina in grado di capire\ncome eseguire i compiti.  Non possiamo. E quello per me è stato il\nmomento in cui tutto ha funzionato. Ma ovviamente, era come nel\n2008, quindi nulla funzionava nell'intelligenza artificiale e solo per altri sette anni si guardò dall'esterno\nal deep learning e al fatto che i computer\nerano diventati abbastanza veloci, da essere ora commercialmente utili, che abbiamo iniziato a realizzare che, guarda, forse c'è davvero\nuna possibilità per realizzare questo sogno. E sai, io e altri ci siamo riuniti perché volevamo vedere se\npotevamo guidare la tecnologia dell'intelligenza artificiale in modo positivo. Volevamo vedere se potevamo\neffettivamente costruire il tipo di macchina di cui aveva parlato Turing, un'intelligenza di livello umano,\nquella che chiamiamo AGI, e che fosse qualcosa\na beneficio di tutta l'umanità. Questa è la missione di OpenAI. Quindi spingiamo avanti la tecnologia. Vogliamo che sia effettivamente\nvantaggioso, che sia sicuro e che distribuisca tali benefici a tutti. Quindi ci stiamo lavorando\normai da otto anni, credo. E in quel momento, continuiamo a svolgere la stessa attività di, costruiamo semplicemente una rete neurale più grande, la rendiamo più capace, la rendiamo più allineata, la rendiamo più sicura. E negli ultimi due anni abbiamo anche iniziato a implementarlo\ne renderlo utile. Ed è questo che penso sia così interessante per me di questa tecnologia. Non è come la fusione dove è come se ce l'avessi oppure no. È ad ogni passo del percorso che\npuoi effettivamente avere un impatto e puoi effettivamente\niniziare a portare benefici alle persone. E quindi penso che sia positivo e sai, puoi vedere i vantaggi\ndi ciò che hai costruito e imparare effettivamente come\nmitigare tutti gli aspetti negativi. E quindi penso che questa sia\nla fase in cui ci troviamo. - Sì, c'è molto in questo. Voglio dire, sai, sembra che in base a quando\nlavori su cose sull'intelligenza artificiale, ho poco più di 10 anni più o poco più\n, più vecchio di te. Ma sai, a metà degli anni Novanta, quando ero al college, stavo lavorando con alcuni\ndei primi pionieri e alcuni di loro erano miei professori ed era la stessa cosa. Ero super entusiasta\ndell’intelligenza artificiale. Leggevo la fantascienza e pensavo, oh, ci\nvorrà un'eternità, se mai accadrà. E proprio secondo te, hai sperimentato la stessa cosa\ncirca 10, 12 anni dopo. E poi, anche quando\nstavate pensando di avviare OpenAI, questo, sapete,\nquello che avete menzionato AGI, Artificial General Intelligence, penso che molte persone riflessive,\nse devo essere sincero, anche me stesso, e tendo a essere piuttosto\nottimista riguardo  cose, avrei pensato che fosse\nun po' delirante, iniziare ora a\nlavorare su un, come, sai, nemmeno un laboratorio di ricerca. Voglio dire, immagino sia una\nspecie di laboratorio di ricerca, ma avviare effettivamente\nun'organizzazione che abbia un... Pensavi che\nte lo dicessero le persone? Comunque come hai deciso di farlo? - O si. Voglio dire, abbiamo ricevuto molti\nfeedback molto, molto negativi dalla community. E la cosa che in realtà ho\ntrovato più interessante è che stavamo parlando della\nsicurezza dell'intelligenza artificiale prima che diventasse interessante. E in effetti ricordo di aver\nparlato con un candidato che lavorava in un grande laboratorio di intelligenza artificiale che disse: \"Sì, penso che la sicurezza dell'AGI sia il problema più importante. Penso che sia davvero importante. Ma se mai mi citassi a\nquesto proposito,  Negherò tutto.\" E penso che questo sia ciò che ci distingue è che eravamo davvero\ndisposti a pensare a dove sarebbe andato e ad agire di conseguenza. Noi non siamo soli. Ad esempio, ci sono altre persone nel campo, altri pionieri che hanno\nspinto avanti questo tipo di tecnologia e, sai, sono stati anche, penso, molto\nvisionari in termini di pensiero, sai,\nanche molti anni avanti rispetto a noi per iniziare a risolvere questo problema. Ma penso che forse, sai, non so se è\nsemplicemente qualcosa nel nostro DNA o se è qualcosa che riguarda\nsemplicemente, sai, per me personalmente, mi sentivo\ncome se avessi passato cinque anni a costruire una tecnologia  azienda. Ero pronto a iscrivermi davvero\nper un problema su cui ero pronto a lavorare per il resto della mia vita. Ed era così chiaro per me che se potessi\napprofondire un po', anche se parliamo 300 anni dopo e arriva l'AGI, ne varrebbe la pena. Giusto? E, sai, c'è la possibilità che ciò accada anche prima. E quindi penso che sia\ngentile l'inquadramento della linea temporale, puoi\ncavillare, puoi dibattere, puoi parlare di queste cose, ma fondamentalmente\niscrivendoti per l'impatto della tecnologia più importante che gli esseri umani potranno mai creare. Come se fosse qualcosa che posso ottenere. - E ciò che è degno di nota, e immagino che questa non sia una\nnovità per molte persone perché OpenAI è stato\nmolto nelle notizie ultimamente è, sai, hai questi\nmodelli GPT, questi, sai, trasformatori generativi pre-addestrati  ,\nquesta tecnologia che è, sapete, un sapore di reti neurali, che è stata nella comunità dell'intelligenza artificiale\nper un po' di tempo, e tutti voi avevate GPT-1, GPT-2, la gente diceva, oh, questo è interessante, può scrivere  , ma, sai, non ha una buona conoscenza della conoscenza,\nGPT-3 ancora meglio. E poi è\nuscito ChatGPT, è un'interfaccia, che inizia a lasciare un\npo' a bocca aperta le persone. E poi ovviamente abbiamo\nannunciato con tutti voi che stiamo lavorando\ninsieme su GPT-4, per usarlo in Khan Academy, ma voi ovviamente avete fatto tutto il lavoro per svilupparlo. Questa nozione di AGI,\nIntelligenza Generale Artificiale, non sembra più così stravagante. Sai, anche parte di\nciò che penso che molte persone abbiano fatto a GPT-4 inizia a sembrare un po' così. Immagino che la mia prima domanda sia: cosa pensate\nche stiate facendo per arrivare a questo punto dove,\nsapete, ci sono molte, molte persone che lavorano nel campo, molte organizzazioni più grandi\ncon più risorse. Pensi che sia qualcosa che\nstai facendo in modo diverso o il modo in cui lo stai affrontando? Sì, cosa pensi che sia speciale? - Sì, penso che sia una domanda corretta. Voglio dire, penso che facciamo parte di una tendenza molto più ampia, giusto? È come una storia molto più ampia, giusto? Guardi indietro a tutte le curve di calcolo, per 70 anni abbiamo avuto\nquesta crescita esponenziale e sai, nel 2000\nRay Kurzweil diceva, ehi, guarda il calcolo, questo\nti dirà cosa sarà possibile. Questo è il carburante per il progresso. E tutti pensavano che fosse pazzo. E ora penso che fondamentalmente\npensino che abbia ragione. E penso che, sai,\nse pensi alla quantità di ingegneria\nnecessaria per poter fornire qualcosa come GPT-4, dall'effettiva\ninfrastruttura di calcolo a tutti i set di dati e gli strumenti che utilizziamo, questo è davvero  questo enorme sforzo dell’umanità in molti modi. Ma in un certo senso,\nsai, siamo riusciti a realizzarlo perché abbiamo\nriunito persone con un background di ricerca\ne un background di ingegneria. E penso che sia qualcosa di davvero unico, giusto? E penso che, sai, la\nsicurezza sia una parte fondamentale di ciò che proviene da\ntutte le diverse angolazioni. È un po', sai, sia in pratica che in teoria,\npensare a cosa, sai, come si comporteranno questi sistemi, come\nandranno bene e come andranno male. Ma sì, penso che la\ncosa che è stata così interessante per me quando abbiamo iniziato, era guardare tutti gli altri\nlaboratori, e puoi davvero vedere che provengono tipicamente da\nun background di ricerca. E così ci sono questi ingegneri ricercatori a cui viene detto cosa fare, e gli scienziati ricercatori\npossono fare quello che vogliono. E tu dici, non\nsembra il modo in cui costruirai effettivamente un sistema funzionante. Sembra un ottimo modo\nper ottenere un sacco di citazioni, ma se vuoi davvero avere un impatto e sviluppare qualcosa, devi solo strutturare l'organizzazione in modo diverso. Ed è difficile, come\nsembra facile sulla carta, ma ci sono questi modi molto contrastanti di pensare alle cose se\nprovieni da un background molto pratico rispetto a se provieni da un background più accademico. E in qualche modo dobbiamo appoggiarci a quelli. E penso che abbiamo\nrisolto versioni più sofisticate di questo tipo\ndi mentalità diverse, background diversi,\nproblemi, come molte, molte volte. E non lo risolvi mai del tutto. Passi a una\nversione più sofisticata. Quindi penso che sia questo\nappoggiarsi al disagio, appoggiarsi alle parti difficili. - No, ho così tante\ndomande perché penso che,\nsai, c'è qualcosa di unico che state facendo tutti. Non siete tutti un'organizzazione così grande e sicuramente, immagino, avete un peso superiore al vostro peso. Ma una delle cose di cui\nhai parlato molto, e questo è stato anche uno\ndei motivi per avviare OpenAI come organizzazione no-profit, e\nparleremo un po' di come le cose si sono evolute da allora, ma  continui a menzionare la sicurezza e, sai, l'intelligenza artificiale è allo stesso tempo eccitante e forse anche spaventosa per alcune persone. Abbiamo tutti letto sia la fantascienza emozionante che quella distopica. Quando parli di sicurezza, di cosa parli? Quali sono le vere paure di cui\nle persone dovrebbero preoccuparsi e porre limiti e quali sono quelle che\nforse non sono così giustificate? - Sì, quindi penso che ci sia\nstata una lunga storia di pensiero sulla sicurezza dell'IA, giusto? E penso che ce ne siano alcuni\nche risalgono a prima degli anni Cinquanta e Sessanta. Puoi trovare persone come Arthur\nC. Clark che parlano di questo, di avere una macchina intelligente. E si sa, ciò che distingue gli esseri umani è il fatto che sono intelligenti. E quindi è qualcosa di nuovo, giusto? Tutta questa idea. E quindi penso che dovremmo affrontarlo con entusiasmo\nper ciò che può essere realizzato e cautela per dove potremmo andare storto. Quindi penso che sia\nfondamentalmente profondamente corretto, provare questi sentimenti contrastanti e allo stesso tempo\nstupirsi di qualcosa di nuovo, ma anche chiedersi dove sta andando e dov'è questo in particolare? Dove potrebbero essere le insidie? Penso che sia l'unico modo in cui\npossiamo navigare correttamente nello spazio. Ma penso che un'altra cosa molto interessante\nsia quanto sorprendente sembri essere l'intelligenza artificiale e come funziona. Come pensi, negli\nanni Novanta tutti pensavano che, oh, se risolvi gli scacchi\nquesto ti porterà all'AGI. E in realtà gli scacchi sono stati la prima cosa che abbiamo\nrisolto in molti modi, e non siamo andati oltre. E penso di aver visto lo stesso riguardo al\npensiero sulla sicurezza, giusto? Che se lo pensi\ncome, oh, come, sai, come una cosa che avrebbe potuto essere costruita, una direzione che penso fosse possibile, era che avresti costruito questi agenti che devono sopravvivere, replicarsi ed evolversi in qualche modo  sorta di complicata simulazione multi-agente. Sembra davvero terrificante, vero? Anche solo sapere di cosa\nsono capaci quegli agenti. E sai, per poterti fidare di loro, devi risolvere alcuni\nproblemi davvero difficili. E quindi ci vuole un grande sforzo\nper pensare a come progettare una funzione di ricompensa che scrivi in ​​modo molto\nspecifico che non ha, fai attenzione a ciò che desideri. E quindi si è pensato molto a questo tipo\ndi modi di risolvere i problemi, ma il paradigma GPT, in un certo senso\n, nessuno se lo aspettava, è semplicemente totalmente diverso da quello che ti aspetteresti dal\npunto di vista della sicurezza. E quindi per me la lezione è davvero questa, sapere anche come\ngestire la tecnologia e capire per cosa\npotrebbe essere utilizzata e come\nguidarla nel modo giusto. Non che ci sia necessariamente\nun limite alla lungimiranza, ma penso che abbiamo una storia di eccessiva fiducia nelle cose sbagliate. E quindi, sai, un esempio in cui puoi vedere una testa è\nse guardi, ad esempio, l' apprendimento per rinforzo\ndalle preferenze umane. E quindi questo è ciò che usiamo per ottimizzare effettivamente i\ncomportamenti di questi modelli. E questo è qualcosa di\nmolto diverso da, ad esempio, GPT-3, dove rilasciamo il modello dopo averlo semplicemente addestrato\nsul set di dati di base a GPT-4, dove siamo effettivamente in\ngrado di ottimizzarlo e in un certo senso scegliere i valori\nche il  mostre di modelli. E in realtà abbiamo iniziato a sviluppare quella tecnologia nel 2017 prima che\nesistesse uno di questi modelli. E quindi penso che tu\npossa vedere un po' più avanti nel futuro. Dovresti pensare a come\nverranno utilizzati, assicurandoti entrambi che siano allineati con ciò che l'operatore vuole, sai, invece, l'utente. Che non sono in alcun modo inutilizzabili se qualcuno vuole fare qualcosa, ma la società ha una\nsocietà che è illegale o dannosa per qualcun altro,\ndovrebbero esserci dei limiti. E poi penso anche che\nci siano effetti sull'ecosistema in cui in qualche modo,\npuoi immaginare che le IA, facciano tutte più o meno quello che gli viene\ndetto di fare a livello locale, ma in qualche modo si aggiunge a un mondo peggiore. E quindi penso che dovremo\n affrontare una serie crescente di posta in gioco col passare del tempo. Sapete,\nin qualche modo ci siamo evoluti rispetto al tipo di rischi di questi modelli. Per GPT-3, penso che fossimo davvero preoccupati per la disinformazione, ma quando siamo arrivati ​​al dunque, abbiamo visto che le persone in realtà\nvolevano solo generare, che il vettore di abuso più comune\nera generare pubblicità mediche per vari farmaci. E penso che con GPT-4\navrai un nuovo tipo di classe di rischi e penso che in futuro avrai nuove\nclassi di benefici e rischi che vanno di pari passo. - Quindi, sai, ovviamente\nuna delle cose che, interessante riguardo al fatto che\nnoi due parliamo nelle nostre organizzazioni, ci avete contattato, sai, sei mesi fa, quando\nstavate appena iniziando a capire  prima versione di GPT-4. E io, immagino che una domanda che\nho sia, sai, perché ci hai contattato allora? - Sì, beh, per quanto mi riguarda personalmente,\nmi sono sempre sentito come una delle motivazioni per\ncostruire sistemi di intelligenza artificiale, per provare a costruire AGI, per dare a tutti un tutor personale, come me personalmente, penso che\nmolte persone abbiano una storia del genere  un insegnante che\nli ha davvero capiti, che li ha aiutati a realizzare ed\nentusiasmarsi per una materia. E immagini cosa\naccadrebbe se tutti avessero accesso a un tutor del genere 24 ore su 24, 7 giorni su 7, che possa davvero capirli\ne motivarli. E sento che questo è molto in linea con ciò che la Khan Academy sta costruendo. E io, lo sai, c'è il potenziale che vuoi sbloccare in ogni studente. E così è stato proprio come quando\nci siamo resi conto che forse potevamo davvero incidere sull'istruzione, forse questo poteva essere applicato lì. Era così chiaro che la Khan Academy fosse il primo porto di scalo. - E da allora, sai, immagino che abbiamo lavorato insieme, e ovviamente ora che il GPT-4 è disponibile, cosa speri che diventi? Ad esempio, come speri che il\nmondo dell'istruzione sfrutti tutto ciò? È noto che l'uscita di ChatGPT causò molto stress\nnel mondo dell'istruzione. La gente diceva, oh, i\nbambini lo useranno per imbrogliare i loro compiti\no fare i compiti. Come dovrebbero\npensarci gli educatori in questo momento? - Sì, penso che\ndirei che esiste una sorta di versione specifica per l'istruzione di ciò che ho detto in generale, giusto? Che ci sono opportunità, ci sono rischi. E penso che capire come orientarsi sia davvero importante. E devi appoggiarti\na quella tensione, giusto? Quindi, penso che sia\nimportante che le persone imparino a pensare con la propria testa, ma penso che sia anche molto importante che gli studenti possano, in un\ncerto senso, ottenere il meglio dalla tecnologia e che\nstiamo rendendo questa tecnologia molto accessibile e  disponibile\nper persone che altrimenti non sarebbero in grado di ottenere ottimi strumenti educativi. E quindi penso che ci sia, sai, la mia speranza è che serviamo come\nuna piattaforma che insegnanti ed educatori siano in grado di\nmodellare a loro piacimento e per aiutare in qualche modo a\nlavorare con i loro studenti e per colmare le lacune che non possono. E quindi, sai, penso che\nil tipo di applicazioni, in realtà sarei un po' curioso, Sal, quelle che hai visto come quelle di cui sei più entusiasta. - Sì. Beh, sai, ovviamente, ci abbiamo messo molto e siamo molto entusiasti, sai, abbiamo anche fatto una dimostrazione di\nquello che chiamiamo Khanmigo, che è essenzialmente l'incarnazione dell'IA  sulla Khan Academy con\nalcuni grandi distretti scolastici, alcuni dei quali hanno notoriamente bandito ChatGPT. E ci stanno dando il feedback, questo è quello che volevamo. Volevamo sfruttare i\npoteri di questa tecnologia, ma abbiamo messo delle barriere attorno ad essa, in modo che venga utilizzata in modo produttivo per gli studenti in modo che, sai, gli insegnanti possano\nvedere cosa stanno facendo, che ora è pedagogicamente valido. Ora, è interessante che si sia creato un dibattito davvero grande in cui le persone pensano, beh,\nè ​​fantastico se sono all'interno della sandbox, ma allora cosa impedisce loro di andare da qualche altra parte? E qualcun altro\ncreerà un'applicazione che utilizza l'API per fare qualcosa, sai, qui o là. Quindi ecco, penso che ci siano\nalcune domande reali lì. Immagino che forse\nlo trasformerò in una domanda, come state pensando\na questo in termini di, sarà un po'\ncome i vostri classici app store dove c'è un\npo' di revisione editoriale su come sono le persone?  utilizzando l'API o sarà più\nsimile a farti sapere, vediamo cosa succede. Come state pensando a questo? E immagino che potremmo parlare\ndi istruzione in generale o di istruzione specifica o in generale. - Sì. Beh, penso che la verità\nsia che questa tecnologia è molto nuova e c'è\nmolto da imparare, giusto? Ma ci teniamo molto. Passiamo molto tempo\na pensare esattamente a come le persone dovrebbero costruire sulle\nnostre piattaforme, a quali dovrebbero essere le regole di coinvolgimento,\ncercando di ottenere molti input. Quindi ci impegniamo molto con gli educatori e con altre persone\ne in vari spazi perché penso che alla fine la decisione su come integrare questo tipo\ndi tecnologia nel mondo non dovrebbe spettare solo a noi. Dobbiamo sicuramente farne parte, se è la nostra tecnologia, ma pensiamo che sia davvero importante ricevere un ampio contributo da tutti. Quindi questa è in realtà una\ncosa che penso sia forse il singolo fattore più importante. E quindi dovresti aspettarti un'evoluzione, giusto? Dovresti aspettarti che otteniamo dati e ci rendiamo conto che, ehi, come questa\ncosa particolare è andata alla grande, questa cosa particolare non ha funzionato, e poi impariamo come adattarci. Quindi la mia speranza è che, sai, numero uno, penso che sia davvero importante mostrare davvero il lato positivo, giusto? Penso che sia facile vedere solo le cose che possono andare storte. E penso che sia importante\nnon nascondere la testa sotto la sabbia, ma il motivo per cui\nlo costruiamo in primo luogo, giusto, è\nrealizzare effettivamente questi benefici. E quindi quello che sono davvero entusiasta\ndi vedere è che la Khan Academy o chiunque altro\ncostruirà in questo spazio per impegnarsi davvero,\nandando in profondità con i distretti, parlando con gli educatori e capendo davvero quale sia la forma esatta che vogliono  . Una volta che hai un\nesempio positivo di qualcosa che funziona, è facile costruire\ndegli standard attorno ad esso, giusto? Se non ce l'hai affatto, stai solo girando nel buio. E lo abbiamo già visto, l' ultima volta che abbiamo ripubblicato un post sul blog\nsugli standard di sicurezza per l'implementazione di modelli linguistici. E tutto ciò deriva da due\nanni di implementazioni e, onestamente, da molti errori. E quindi penso che questa\nimplementazione iterativa dell'apprendimento dalla pratica,\nsia, penso, la cosa più importante che tutti noi possiamo fare in questo momento. - No, sono completamente d'accordo. Chiaramente, stiamo investendo così tanto perché siamo\ngeneralmente molto ottimisti su dove sta andando tutto questo. E sai, non potevo parlarne apertamente\nquando c'erano tutti questi dibattiti su ChatGPT nei media, ma poi una volta che abbiamo potuto\nfarlo, dicevo, guarda, questo, so che c'è qualche timore, ma se tu  mettilo nel giusto quadro con i giusti guardrail, non solo puoi mitigare questi rischi, ma puoi avere enormi progressi, un tutor per ogni studente\ne semplicemente introdurre modalità completamente nuove che sarebbero sembrate\nfantascienza senza l'intelligenza artificiale, cose come  intervista un personaggio storico, esercita le tue capacità di dibattito. Sai, potremmo andare,\nsai, gli insegnanti possono aiutare a creare\npiani di lezione, eccetera, eccetera. Sapete, ultimamente\nho avuto un dibattito con molti amici,\namici esperti che conoscono l'intelligenza artificiale, eccetera, siamo entrati in\nquesto classico dibattito sul fatto che lo strumento\ndiminuirà le capacità umane o espanderà  capacità umana? Sono dalla parte dell'espansione. Quindi, sai, ecco dove sono le mie carte, che ci renderanno più creativi. In qualche strano modo, potrebbe\neffettivamente farci scrivere di più perché saremo più editori e creeremo di più. Ma io, come pensi a questo quando la gente dice, oh wow, sai, ora le persone avranno solo una\ncosa in meno che fanno gli umani, non svilupperanno le\nloro capacità di scrittura, non svilupperanno la creatività '  perché per questo si affideranno molto di più\nall'intelligenza artificiale. - Sì, voglio dire, sono decisamente con te, Sal. Ad esempio, penso che\nl'effetto netto sarà estremamente positivo,\npenso che otterremo tutti questi superpoteri dell'IA, possiamo ottenere cose che\naltrimenti non potremmo ottenere. La fatica se ne andrà. Tutte quelle cose che\npenso siano qui, giusto? Se non all'orizzonte. Ma ovviamente sarebbe\nnascondere la testa sotto la sabbia dire che è solo l'unico effetto, giusto? Penso che questo sia l'effetto netto e penso che sarà abbastanza forte. Ma penso che ci\nsaranno aneddoti di posti in cui, sai, sì, è come se le persone amassero un mestiere particolare e ora quel mestiere è mercificato, giusto? Che c'era una barriera all'ingresso. Dovevi sviluppare un'abilità\ne ora chiunque può farlo. E da un lato è\nuna cosa bellissima, no? Perché ci sono tutte queste\npersone la cui creatività ora può essere sbloccata, giusto? Ci sono, sai, tutti, sai, proprio come pensi tu, quante persone hanno uno smartphone? Quindi, se riesci a garantire l'\naccesso a un'intelligenza artificiale molto potente a chiunque abbia uno smartphone e loro possono iniziare a creare in un modo che prima dovresti acquistare un sacco di software professionale e\ndovresti andare a  scuola e ricevere molta formazione. Come se potessi vedere come\nquel mondo sia diverso. Ma per molti versi è più\npositivo, sai, in questo. Ma penso che questo cambiamento e l'essere preparati per quello, sia una cosa spaventosa. E penso che sia\nqualcosa che dovremmo considerare con gli occhi ben aperti. - Sì, assolutamente. E sai, proprio nel\ntempo che ci resta, ogni volta che ti parlo,\ntu, a volte dici, oh, e comunque Sal,\nstiamo lavorando anche su questo. E poi lo dici, mostramelo e io dico, oh, è un grosso problema. Tipo, sai, è come e c'è di più. Concludiamo questa conversazione semplicemente, sai, dipingendo un\nquadro per la gente di ciò che sta arrivando, il più\npossibile parlarne e quali pensate siano le implicazioni e come state cercando di concentrarvi su una di quelle direzioni o  un altro. - Sì, beh guarda, penso\nal livello più alto, come se fossimo davvero seri\nriguardo a questo percorso verso l'AGI. Come se pensassimo che questa sia la traiettoria su cui si trova la società, il mondo. Penso che sia un percorso che\nstiamo seguendo da molto tempo. Se guardi tutte queste curve e sai, penso che abbiamo\nraccolto il testimone in molti modi e sentiamo che è\nnostra responsabilità principale non solo costruirlo,\nma costruirlo, giusto? E nel breve termine, penso che si vedano\ncose come, sai, GPD 4 ha input visivi. È qualcosa che\nstiamo ancora sperimentando con un partner. Ma penso che\nanche questa sarà una nuova funzione in termini di usabilità, giusto? Che sarai in grado di presentare documenti, sarai in grado di farlo, sai, se hai un diagramma\nche fa parte, sai, del curriculum educativo di Khan Academy e che comprenda\nquel diagramma insieme alla domanda degli studenti  a\nriguardo è importante. Sarai in grado di farlo. E quindi penso che apriremo\n l'accessibilità in\nmolti modi, sai, rendendo queste cose più veloci,\npiù economiche e più accessibili. Questo è sempre un grande obiettivo per noi. E sto davvero cercando di migliorare. Penso che la cosa che\nci manca in questo momento in molti modi sia la capacità di\ngenerare nuove idee, giusto? Essere in grado di risolvere problemi più difficili e tutto ciò a cui stiamo pensando, stiamo esplorando e, sai, ancora una volta, lo facciamo con il nostro\nfocus sulla sicurezza. - Sì, beh devo dire Greg, sai, grazie mille per averci dedicato il tempo e averci portato in questo viaggio perché sembra davvero di\nvivere in un libro di fantascienza ed è una specie di uno di questi: scegli la tua\navventura  libri di fantascienza in cui può andare in direzioni diverse, ma penso che finché ci saranno\nabbastanza persone che pensano a come massimizzare le\nopportunità e i benefici e mitigare il maggior numero di rischi possibile, lo farò, e sembra che anche tu lo siamo  piuttosto entusiasta di come potrebbe essere il mondo a\ncausa di questo. - Anch'io, sì, è stato bellissimo chiacchierare. - Ottimo, grazie per esserti unito. - Sì, grazie."
}